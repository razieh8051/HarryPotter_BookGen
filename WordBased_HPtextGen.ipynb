{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process:<br>\n",
    "1-Load the data<br>\n",
    "2-Preprocess the data(tokenizing punctualtion, lower case except for names, split)<br>\n",
    "3-Create dictionary from the words<br>\n",
    "4-Build and train the model<br>\n",
    "5-Generate the new text<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import warnings\n",
    "import re\n",
    "from tensorflow.contrib import legacy_seq2seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "f = open(\"HarryPotterCh1_SorcererStone.txt\",\"r\") \n",
    "textbook = f.read()\n",
    "#print(textbook)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create our own function for preprocessing, tokenization as well as creating index of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(string):\n",
    "    #Tokenize the punctuations in order to consider them as words\n",
    "    string = string.replace(\"\\n\", \" nextline \")\n",
    "    string = string.replace(\".\", \" periodmark\")\n",
    "    string = string.replace(\":\", \" colonmark\")\n",
    "    string = string.replace(\";\", \" semicolonmark\")\n",
    "    string = string.replace(\",\", \" commamark\")\n",
    "    string = string.replace(\"?\", \" questionmark\")\n",
    "    string = string.replace(\"!\", \" exclamationmark\")\n",
    "    string = string.replace(\"...\", \" 3dots\")\n",
    "    string = string.replace(\"--\", \" 2dashes\")\n",
    "    string = string.replace(\"\\\"\", \" quotemark\")\n",
    "    string = string.replace(\"(\", \" leftparan\")\n",
    "    string = string.replace(\")\", \" rightparan\")\n",
    "    \n",
    "    #Names to remain capitalized\n",
    "    Names = ['Harry', 'Potter', 'James','Jim', 'Abbott','George','Hannah', 'Susan', 'Bones', 'Minerva','McGonagall','Professor',\n",
    "             'Sprout','Malfoy','Draco','Voldemort','Rubeus','Percy','Snape','Weasley','Hagrid','Fred','Scabbers','Hedwig',\n",
    "            'Sirius','Hermione','Granger','Ronald','Peeves','Vernon','Dursley','Mrs.','Mr.','Norris','Argus','Filch','Nick','Charlie','Neville',\n",
    "             'Quirrell','Dumbledore','Filch','Flitwick','McGonagall','McGuffin','Ollivander','Baron','Pomfrey','Gryffindor','Slytherin',\n",
    "             'Ravenclaw','Hufflepuff']\n",
    "\n",
    "    toLower = lambda x: \" \".join( a if a in Names else a.lower()\n",
    "            for a in x.split() )\n",
    "\n",
    "    string= toLower(string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text=preprocess_text(textbook)\n",
    "#print(text)\n",
    "text_words=text.split()\n",
    "text_len=len(text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary from list of words in text\n",
    "def dictionary(words):\n",
    "    #create list of words without their dupications \n",
    "    words=set(words)\n",
    "    #map word to index\n",
    "    indx = {key: i for i, key in enumerate(words)}\n",
    "    return indx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert from index to words\n",
    "def get_by_key_dict(indx_word,words_dict):\n",
    "    for word, indx in words_dict.iteritems():    \n",
    "        if indx == indx_word:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"periodmark'\\xe2\\x80\\x9c\": 0,\n",
       " 'wrought-iron': 1,\n",
       " 'both': 2739,\n",
       " 'foul': 16,\n",
       " 'four': 3,\n",
       " 'woods': 4,\n",
       " 'spiders': 5,\n",
       " 'ornate': 25,\n",
       " 'fiddling': 5681,\n",
       " 'wizardry': 7,\n",
       " 'Ronald': 8,\n",
       " \"fluffy's\": 9,\n",
       " 'lord': 10,\n",
       " 'flicking': 11,\n",
       " 'three-thirty': 12,\n",
       " 'sinking': 13,\n",
       " 'figg': 14,\n",
       " \"quotemarkwhat's\": 15,\n",
       " 'yellow': 2,\n",
       " 'bringing': 113,\n",
       " 'disturb': 18,\n",
       " 'basics': 19,\n",
       " 'wooden': 20,\n",
       " 'wednesday': 21,\n",
       " 'quotemarkhurry': 22,\n",
       " 'specially': 23,\n",
       " 'tired': 24,\n",
       " 'hanging': 6,\n",
       " 'bacon': 26,\n",
       " 'second': 27,\n",
       " 'crisply': 28,\n",
       " 'sailed': 29,\n",
       " 'scraped': 30,\n",
       " 'leftparantwo': 31,\n",
       " 'iron-gray': 32,\n",
       " 'thunder': 33,\n",
       " 'fingers': 34,\n",
       " \"'smatter\": 35,\n",
       " 'pawed': 36,\n",
       " 'quotemarkhold': 37,\n",
       " 'pressed': 38,\n",
       " 'Neville': 39,\n",
       " 'hero': 40,\n",
       " '-then': 41,\n",
       " \"norris's\": 42,\n",
       " 'here': 43,\n",
       " 'reported': 44,\n",
       " 'ashen-faced': 45,\n",
       " 'shriek': 46,\n",
       " 'kids': 47,\n",
       " 'quotemarkhas': 48,\n",
       " 'climbed': 49,\n",
       " 'reports': 50,\n",
       " 'quotemarkhad': 51,\n",
       " \"i'd\": 52,\n",
       " 'transfixed': 53,\n",
       " \"i'm\": 54,\n",
       " 'golden': 55,\n",
       " 'explained': 56,\n",
       " 'brought': 57,\n",
       " 'stern': 58,\n",
       " 'cheating': 59,\n",
       " 'spoke': 60,\n",
       " 'Vernon': 61,\n",
       " 'music': 62,\n",
       " 'therefore': 63,\n",
       " \"wine's\": 64,\n",
       " 'until': 65,\n",
       " 'relax': 66,\n",
       " 'hurt': 67,\n",
       " 'glass': 68,\n",
       " \"quotemarkharry's\": 69,\n",
       " 'tying': 70,\n",
       " 'quotemarkknew': 71,\n",
       " 'midst': 419,\n",
       " 'hold': 73,\n",
       " 'circumstances': 74,\n",
       " 'locked': 75,\n",
       " 'plunged': 76,\n",
       " 'locker': 77,\n",
       " 'quotemarkrun': 5586,\n",
       " 'wand': 79,\n",
       " 'dragons': 80,\n",
       " 'caution': 81,\n",
       " 'want': 82,\n",
       " 'groaned': 83,\n",
       " 'damage': 84,\n",
       " 'how': 85,\n",
       " 'hot': 86,\n",
       " 'hop': 87,\n",
       " 'ronnie': 88,\n",
       " 'beauty': 89,\n",
       " 'leftparangrade': 90,\n",
       " 'outlawed': 91,\n",
       " 'wrong': 92,\n",
       " 'quotemarkoooooh': 93,\n",
       " 'destined': 94,\n",
       " 'types': 95,\n",
       " 'wins': 96,\n",
       " 'quotemarksilence': 97,\n",
       " 'sickening': 98,\n",
       " 'snowballs': 99,\n",
       " 'keeps': 100,\n",
       " 'wing': 101,\n",
       " 'wind': 102,\n",
       " 'wine': 103,\n",
       " \"'jordan\": 104,\n",
       " 'dreamed': 105,\n",
       " 'quotemarktricky': 106,\n",
       " 'whizzing': 107,\n",
       " 'leg-locker': 5593,\n",
       " 'diagonally': 109,\n",
       " 'fir': 110,\n",
       " 'wickedly': 111,\n",
       " 'fit': 112,\n",
       " 'screaming': 17,\n",
       " 'fix': 679,\n",
       " 'fie': 115,\n",
       " 'hidden': 116,\n",
       " 'admirable': 117,\n",
       " 'easier': 118,\n",
       " 'ledgers': 1125,\n",
       " 'corridor': 120,\n",
       " \"weasleys'\": 121,\n",
       " 'quotemarkoooooooh': 122,\n",
       " 'jinxing': 123,\n",
       " 'sixteen': 124,\n",
       " 'silver': 125,\n",
       " 'towered': 126,\n",
       " 'arrow': 128,\n",
       " 'dumpy': 129,\n",
       " 'loyalties': 130,\n",
       " 'interfering': 131,\n",
       " 'blushed': 132,\n",
       " 'weirdos': 133,\n",
       " 'snakes': 134,\n",
       " 'liquids': 6166,\n",
       " 'spider': 135,\n",
       " \"we'd\": 136,\n",
       " 'knitting': 1127,\n",
       " 'blinded': 138,\n",
       " 'ice-cold': 139,\n",
       " 'quotemarksomeone': 140,\n",
       " 'centaurs': 141,\n",
       " 're': 842,\n",
       " 'quotemarksir': 143,\n",
       " 'stamping': 144,\n",
       " 'assured': 145,\n",
       " 'quotemarkpercy': 146,\n",
       " 'pumpkins': 147,\n",
       " 'checked': 2259,\n",
       " 'quotemarkare': 149,\n",
       " 'enormous': 150,\n",
       " 'ate': 151,\n",
       " 'shelves': 152,\n",
       " 'cauldrons': 153,\n",
       " 'scruff': 154,\n",
       " 'bated': 155,\n",
       " 'speedy': 156,\n",
       " 'potions': 157,\n",
       " 'speeds': 158,\n",
       " 'purpose': 4502,\n",
       " 'playfully': 160,\n",
       " 'wash': 161,\n",
       " 'spinning': 162,\n",
       " 'wasn': 163,\n",
       " 'bitten': 164,\n",
       " 'basketball': 165,\n",
       " 'service': 166,\n",
       " 'scared-looking': 167,\n",
       " 'needed': 168,\n",
       " \"dumbledore's\": 5602,\n",
       " 'master': 169,\n",
       " 'legs': 170,\n",
       " 'bitter': 171,\n",
       " 'rummaged': 172,\n",
       " 'listen': 173,\n",
       " 'phoenixes': 174,\n",
       " 'frowned': 175,\n",
       " 'popkin': 176,\n",
       " 'motionless': 177,\n",
       " 'quotemarkthomas': 178,\n",
       " 'lunged': 1042,\n",
       " 'positively': 180,\n",
       " 'showed': 181,\n",
       " 'coward': 182,\n",
       " 'tree': 183,\n",
       " 'whinging': 184,\n",
       " 'idly': 185,\n",
       " 'bodyguards': 186,\n",
       " 'feeling': 187,\n",
       " 'well-': 189,\n",
       " 'quotemarktroll': 190,\n",
       " 'dozen': 191,\n",
       " 'affairs': 192,\n",
       " 'escalator': 193,\n",
       " 'concrete': 1137,\n",
       " 'responsible': 195,\n",
       " 'eagerly': 196,\n",
       " 'doors': 198,\n",
       " 'grips': 199,\n",
       " 'committing': 200,\n",
       " 'duddydums': 201,\n",
       " 'shall': 202,\n",
       " 'quotemarkcheer': 203,\n",
       " 'object': 204,\n",
       " 'looming': 205,\n",
       " 'toil': 206,\n",
       " 'hushing': 207,\n",
       " 'mouth': 208,\n",
       " 'letter': 209,\n",
       " 'erised': 210,\n",
       " 'pearly-white': 211,\n",
       " 'sweetums': 212,\n",
       " 'nettle': 213,\n",
       " 'put-outer': 214,\n",
       " 'scream': 215,\n",
       " 'came': 216,\n",
       " 'saying': 217,\n",
       " 'lessons': 219,\n",
       " 'touches': 220,\n",
       " 'busy': 221,\n",
       " 'clicked': 222,\n",
       " 'shuffling': 223,\n",
       " 'bush': 224,\n",
       " 'touched': 225,\n",
       " 'rich': 226,\n",
       " 'rice': 227,\n",
       " 'plate': 228,\n",
       " 'petrified': 5610,\n",
       " 'stammered': 230,\n",
       " 'firenze': 231,\n",
       " 'pocket': 232,\n",
       " 'cushion': 233,\n",
       " 'quotemarkquidditch': 234,\n",
       " 'tips': 3334,\n",
       " 'spilling': 236,\n",
       " 'tights': 237,\n",
       " 'patch': 238,\n",
       " 'you-know-what': 239,\n",
       " 'lurched': 240,\n",
       " 'flanked': 241,\n",
       " 'boarded': 242,\n",
       " 'blew': 243,\n",
       " 'fair': 244,\n",
       " 'fail': 245,\n",
       " 'hammer': 246,\n",
       " 'best': 247,\n",
       " 'quotemarkmake': 248,\n",
       " 'quotemarkn-not': 2273,\n",
       " 'lots': 250,\n",
       " 'stamps': 251,\n",
       " 'score': 252,\n",
       " 'quotemarknope': 253,\n",
       " 'claws': 254,\n",
       " 'never': 3339,\n",
       " 'quotemarkpositive': 256,\n",
       " 'rolled': 257,\n",
       " 'smelled': 258,\n",
       " 'paddington': 259,\n",
       " 'debt': 260,\n",
       " 'pity': 261,\n",
       " 'accident': 262,\n",
       " 'country': 263,\n",
       " 'askew': 264,\n",
       " 'vomitflavored': 265,\n",
       " 'planned': 266,\n",
       " 'logic': 4026,\n",
       " 'argue': 268,\n",
       " 'tinge': 269,\n",
       " 'asked': 270,\n",
       " 'vain': 271,\n",
       " 'gleaming': 272,\n",
       " 'blonde': 273,\n",
       " 'summat': 274,\n",
       " 'quotemarkdifficult': 276,\n",
       " 'breathlessly': 277,\n",
       " 'much': 278,\n",
       " 'chucked': 279,\n",
       " 'stadium': 280,\n",
       " 'tallest': 281,\n",
       " 'life': 282,\n",
       " \"quotemarkc'mon\": 283,\n",
       " 'malfoys': 284,\n",
       " 'snap': 285,\n",
       " 'substance': 286,\n",
       " 'child': 287,\n",
       " 'worked': 288,\n",
       " 'flooding': 289,\n",
       " 'quotemarkbin': 290,\n",
       " 'remembering': 291,\n",
       " 'doormat': 292,\n",
       " 'played': 293,\n",
       " 'player': 294,\n",
       " 'quotemarkshe': 3348,\n",
       " 'trusted': 297,\n",
       " 'damaged': 298,\n",
       " \"quotemarkquirrell's\": 299,\n",
       " 'taped': 3349,\n",
       " 'things': 301,\n",
       " 'swarthy': 302,\n",
       " 'split': 303,\n",
       " 'quotemarktransfiguration': 304,\n",
       " 'boiled': 305,\n",
       " 'remembrall': 306,\n",
       " 'marched': 307,\n",
       " 'tune': 308,\n",
       " 'echoed': 309,\n",
       " 'thing*': 310,\n",
       " 'echoes': 311,\n",
       " 'sleeps': 312,\n",
       " 'sleepy': 313,\n",
       " 'spectacles': 314,\n",
       " 'ham': 315,\n",
       " 'old-fashioned': 316,\n",
       " \"goblin's\": 317,\n",
       " 'had': 318,\n",
       " 'hag': 319,\n",
       " 'innocent': 1939,\n",
       " 'has': 321,\n",
       " 'hat': 322,\n",
       " 'unblinkingly': 323,\n",
       " 'casually': 324,\n",
       " \"quotemark'oh\": 325,\n",
       " 'possible': 326,\n",
       " 'possibly': 327,\n",
       " 'sleep-': 328,\n",
       " 'shadow': 329,\n",
       " 'quotemarktiptoe': 330,\n",
       " 'bushy': 331,\n",
       " 'desire': 332,\n",
       " 'remind': 333,\n",
       " 'pavement': 334,\n",
       " 'steps': 335,\n",
       " 'meringue': 336,\n",
       " \"constrictor's\": 337,\n",
       " 'right': 338,\n",
       " 'old': 339,\n",
       " 'drowned': 3354,\n",
       " 'crowd': 341,\n",
       " 'people': 342,\n",
       " 'crown': 343,\n",
       " 'quotemarkmere': 344,\n",
       " 'quotemarkvoldemort': 345,\n",
       " 'creep': 346,\n",
       " 'enemies': 347,\n",
       " 'gasps': 348,\n",
       " 'quotemarkup': 349,\n",
       " 'ruffled': 350,\n",
       " 'for': 351,\n",
       " 'bottom': 352,\n",
       " 'quotemarkbecause': 5713,\n",
       " \"quotemarkyou'd\": 353,\n",
       " 'quotemarkum': 354,\n",
       " 'pinched': 355,\n",
       " 'substitutes': 356,\n",
       " 'losing': 357,\n",
       " 'shaken': 358,\n",
       " 'boiling': 5631,\n",
       " 'riffraff': 360,\n",
       " 'stoked': 361,\n",
       " 'festoons': 362,\n",
       " 'slightly': 363,\n",
       " 'meddle': 364,\n",
       " 'raised': 365,\n",
       " 'sob': 366,\n",
       " 'son': 367,\n",
       " \"potter's\": 368,\n",
       " 'thankful': 369,\n",
       " 'beings': 370,\n",
       " 'half-and-half': 371,\n",
       " 'quotemarkmaybe': 372,\n",
       " 'tailcoats': 373,\n",
       " 'tame': 374,\n",
       " \"'up\": 375,\n",
       " \"boy's\": 376,\n",
       " \"minute's\": 377,\n",
       " 'greatness': 378,\n",
       " 'overhead': 3361,\n",
       " 'happy': 380,\n",
       " 'quotemarkb-b-but': 381,\n",
       " 'shrilly': 382,\n",
       " 'peppermints': 383,\n",
       " 'quotemarkeverywhere': 384,\n",
       " 'duel': 385,\n",
       " \"else's\": 386,\n",
       " 'inside': 387,\n",
       " 'smashed': 388,\n",
       " 'panels': 389,\n",
       " 'feet': 6007,\n",
       " 'later': 5636,\n",
       " 'bathrobe': 391,\n",
       " 'soothe': 392,\n",
       " 'sprouts': 393,\n",
       " \"myst'ry\": 394,\n",
       " 'dealer': 395,\n",
       " 'crutches': 396,\n",
       " 'dotted': 397,\n",
       " 'floor': 398,\n",
       " 'smell': 399,\n",
       " 'roll': 400,\n",
       " \"'t\": 401,\n",
       " 'palms': 402,\n",
       " 'devon': 403,\n",
       " 'miranda': 404,\n",
       " 'rolling': 405,\n",
       " '-harry': 3369,\n",
       " 'hygienic': 408,\n",
       " 'fastened': 409,\n",
       " 'sniffed': 410,\n",
       " 'time': 411,\n",
       " 'push': 412,\n",
       " 'gown': 413,\n",
       " 'whoever': 414,\n",
       " 'quotemarkcoming': 416,\n",
       " '90': 1895,\n",
       " 'chair': 418,\n",
       " 'hole': 72,\n",
       " 'foribidden': 420,\n",
       " 'gorgons': 421,\n",
       " 'blood-red': 422,\n",
       " \"quotemarkwood's\": 423,\n",
       " 'icing': 424,\n",
       " 'jerk': 425,\n",
       " 'choice': 426,\n",
       " \"bott's\": 427,\n",
       " 'gloomy': 428,\n",
       " 'right-handed': 429,\n",
       " 'exact': 430,\n",
       " 'minute': 431,\n",
       " 'getups': 432,\n",
       " '1709': 433,\n",
       " \"questionmark'\": 434,\n",
       " 'leave': 435,\n",
       " 'team': 437,\n",
       " 'loads': 438,\n",
       " 'bonfire': 439,\n",
       " 'sixty-five': 440,\n",
       " 'prevent': 441,\n",
       " 'sigh': 442,\n",
       " 'sign': 443,\n",
       " \"'you-\": 444,\n",
       " 'quotemarkdudley': 445,\n",
       " 'crackpot': 446,\n",
       " 'melt': 447,\n",
       " 'lazily': 448,\n",
       " 'falling': 449,\n",
       " 'crashing': 4654,\n",
       " 'leftparanfive': 451,\n",
       " 'quotemarks-s-sorry': 2728,\n",
       " 'funeral': 453,\n",
       " 'address': 454,\n",
       " 'alone': 455,\n",
       " 'along': 456,\n",
       " 'twelve-foot': 457,\n",
       " 'hurtling': 458,\n",
       " 'dusty': 2779,\n",
       " \"second's\": 460,\n",
       " 'wherever': 461,\n",
       " 'carpets': 462,\n",
       " 'love': 463,\n",
       " 'radish': 464,\n",
       " 'prefer': 465,\n",
       " 'bloody': 466,\n",
       " 'shields': 4818,\n",
       " 'crammed': 468,\n",
       " 'toppled': 469,\n",
       " 'working': 470,\n",
       " 'whittled': 471,\n",
       " 'angry': 472,\n",
       " 'tightly': 473,\n",
       " 'wondering': 474,\n",
       " 'broken-down': 475,\n",
       " 'wicked': 476,\n",
       " 'marbles': 477,\n",
       " 'afford': 478,\n",
       " 'everywhere': 479,\n",
       " 'riders': 480,\n",
       " 'anything': 1185,\n",
       " 'jewel-bright': 482,\n",
       " 'pretend': 483,\n",
       " 'believes': 484,\n",
       " 'believed': 485,\n",
       " 'toffee': 486,\n",
       " 'admired': 488,\n",
       " 'frogs': 489,\n",
       " 'broomshed': 490,\n",
       " 'hides': 491,\n",
       " 'allowed': 492,\n",
       " 'quotemarkgot': 493,\n",
       " 'quotemarkcould': 494,\n",
       " 'quotemarkback': 495,\n",
       " 'winter': 496,\n",
       " 'buttered': 497,\n",
       " 'poking': 498,\n",
       " 'elephant': 499,\n",
       " 'spot': 500,\n",
       " 'date': 501,\n",
       " 'such': 502,\n",
       " 'filthy': 503,\n",
       " 'lids': 504,\n",
       " 'natural': 505,\n",
       " 'st': 506,\n",
       " 'darkened': 507,\n",
       " 'so': 508,\n",
       " 'swollen': 509,\n",
       " 'pulled': 510,\n",
       " 'wastepaper': 511,\n",
       " 'years': 512,\n",
       " 'course': 513,\n",
       " 'bucking': 514,\n",
       " 'tore': 515,\n",
       " 'jig': 516,\n",
       " 'yawning': 517,\n",
       " 'nearsighted': 519,\n",
       " 'paraded': 520,\n",
       " 'torn': 521,\n",
       " 'suspicion': 522,\n",
       " 'thump': 523,\n",
       " 'suspension': 524,\n",
       " 'quotemarktaking': 525,\n",
       " 'instantly': 526,\n",
       " 'matches': 527,\n",
       " 'smarter': 528,\n",
       " 'quotemarkfunny': 529,\n",
       " 'smarten': 530,\n",
       " 'arriving': 531,\n",
       " 'sorted': 532,\n",
       " \"yeh've\": 533,\n",
       " 'ketchup': 534,\n",
       " 'chappie': 535,\n",
       " 'leftparanfeeling': 536,\n",
       " 'bowling': 537,\n",
       " 'veins': 538,\n",
       " 'quarter': 539,\n",
       " 'repaired': 540,\n",
       " 'square': 541,\n",
       " 'bursting': 542,\n",
       " 'gloomy-looking': 543,\n",
       " 'entering': 544,\n",
       " 'beetle': 545,\n",
       " 'troll': 546,\n",
       " 'jokes': 5665,\n",
       " 'contained': 3303,\n",
       " 'exploding': 549,\n",
       " 'squares': 550,\n",
       " 'facedown': 551,\n",
       " 'seventh': 552,\n",
       " 'quite': 553,\n",
       " 'complicated': 554,\n",
       " \"-they're\": 3360,\n",
       " 'training': 556,\n",
       " 'dunno': 557,\n",
       " 'massive': 3388,\n",
       " 'hooch': 560,\n",
       " 'saving': 561,\n",
       " 'spoken': 562,\n",
       " 'potter': 563,\n",
       " \"meddlin'\": 564,\n",
       " 'one': 565,\n",
       " 'open': 566,\n",
       " 'dursleys': 567,\n",
       " 'ripping': 568,\n",
       " 'city': 569,\n",
       " 'bite': 570,\n",
       " 'seventy-': 571,\n",
       " 'uric': 572,\n",
       " 'quotemarkwe': 573,\n",
       " '2': 574,\n",
       " 'stuffed': 575,\n",
       " 'bits': 576,\n",
       " 'owl-free': 577,\n",
       " 'lingering': 578,\n",
       " 'proving': 579,\n",
       " 'meddling': 580,\n",
       " 'snatch': 581,\n",
       " 'ridiculous': 582,\n",
       " \"quotemarkshan't\": 583,\n",
       " 'surged': 584,\n",
       " 'pheasants': 585,\n",
       " 'depressed': 586,\n",
       " 'favors': 587,\n",
       " 'coats': 588,\n",
       " \"quotemarklet's\": 589,\n",
       " 'future': 590,\n",
       " 'wandering': 591,\n",
       " 'tasted': 592,\n",
       " 'nicer': 593,\n",
       " 'round-faced': 594,\n",
       " 'turned': 595,\n",
       " 'afternoons': 3573,\n",
       " 'alley': 3575,\n",
       " 'sad': 598,\n",
       " 'say': 599,\n",
       " 'buried': 600,\n",
       " 'lurking': 601,\n",
       " 'saw': 602,\n",
       " 'sat': 603,\n",
       " 'aside': 604,\n",
       " 'zoo': 605,\n",
       " 'note': 606,\n",
       " 'take': 607,\n",
       " 'wanting': 608,\n",
       " 'blinding': 609,\n",
       " 'atop': 1208,\n",
       " 'that-that': 611,\n",
       " \"teacher's\": 612,\n",
       " 'handing': 613,\n",
       " \"c'mere\": 614,\n",
       " 'opposite': 615,\n",
       " 'syllable': 616,\n",
       " 'knew': 617,\n",
       " 'knee': 618,\n",
       " 'pages': 619,\n",
       " 'lawn': 620,\n",
       " 'drive': 621,\n",
       " 'crooked': 622,\n",
       " \"wantin'\": 623,\n",
       " 'trembled': 624,\n",
       " 'laws': 625,\n",
       " 'walking': 626,\n",
       " \"d-d-don't\": 627,\n",
       " 'bright': 628,\n",
       " 'imagined': 629,\n",
       " 'slot': 630,\n",
       " 'merlin': 631,\n",
       " \"quotemarkcouldn't\": 632,\n",
       " 'cloak': 633,\n",
       " 'tears': 634,\n",
       " 'going': 635,\n",
       " \"bidin'\": 636,\n",
       " \"periodmark'\": 3803,\n",
       " 'robe': 638,\n",
       " 'guarded': 639,\n",
       " 'assistant': 640,\n",
       " 'freezing': 641,\n",
       " 'cursing': 642,\n",
       " 'streak': 6311,\n",
       " 'awaiting': 643,\n",
       " 'hinges': 644,\n",
       " 'saliva': 645,\n",
       " 'borrow': 646,\n",
       " 'worried': 647,\n",
       " \"goin'\": 648,\n",
       " \"could've\": 649,\n",
       " 'bombs': 650,\n",
       " 'where': 651,\n",
       " 'vision': 652,\n",
       " 'corridors': 5679,\n",
       " 'raged': 654,\n",
       " 'dived': 655,\n",
       " 'horned': 1214,\n",
       " 'dives': 657,\n",
       " 'jumped': 3960,\n",
       " \"quotemarkdon'\": 659,\n",
       " 'dormitory': 660,\n",
       " 'quotemarkstupid': 661,\n",
       " 'moldy': 662,\n",
       " 'moons': 663,\n",
       " 'enjoys': 664,\n",
       " 'gives': 5606,\n",
       " 'youknow-who': 665,\n",
       " \"hermione's\": 666,\n",
       " 'Malfoy': 667,\n",
       " 'concentrate': 668,\n",
       " 'quotemarkthirty-nine': 669,\n",
       " \"you-know-who's\": 670,\n",
       " 'many': 671,\n",
       " 'thickly': 672,\n",
       " 'flipped': 673,\n",
       " 'quotemarkparkinson': 3406,\n",
       " 's': 675,\n",
       " 'loudly': 676,\n",
       " 'mane': 677,\n",
       " 'expression': 678,\n",
       " 'backpack': 114,\n",
       " \"can't\": 680,\n",
       " 'twin': 681,\n",
       " 'twig': 682,\n",
       " 'boat': 683,\n",
       " 'math': 4740,\n",
       " 'better': 3407,\n",
       " 'teddy': 685,\n",
       " 'stretch': 686,\n",
       " 'west': 687,\n",
       " 'vacation': 688,\n",
       " 'breath': 689,\n",
       " 'wants': 690,\n",
       " 'cliodna': 691,\n",
       " 'lanes': 692,\n",
       " 'thousand': 693,\n",
       " 'photos': 694,\n",
       " 'tightened': 695,\n",
       " 'queasy': 696,\n",
       " \"quotemarkthat's\": 697,\n",
       " 'ghoulie': 698,\n",
       " 'newspaper': 699,\n",
       " 'passes': 6009,\n",
       " 'snuffbox': 700,\n",
       " 'threequarters': 701,\n",
       " 'quotemarkupf': 702,\n",
       " 'limping': 703,\n",
       " 'quotemarknott': 704,\n",
       " 'ivy': 705,\n",
       " 'rooting': 706,\n",
       " \"-i'm\": 707,\n",
       " 'quotemarkbrilliant': 708,\n",
       " 'strange-looking': 710,\n",
       " 'edged': 711,\n",
       " \"figure's\": 712,\n",
       " 'cheers': 713,\n",
       " 'edges': 714,\n",
       " 'quotemarkthere': 2348,\n",
       " 'cheery': 716,\n",
       " 'flocks': 717,\n",
       " 'pacing': 718,\n",
       " 'pewter': 4390,\n",
       " 'quotemarkneville': 720,\n",
       " 'summer': 721,\n",
       " 'being': 722,\n",
       " 'rest': 723,\n",
       " 'slimy': 724,\n",
       " 'fateful': 725,\n",
       " 'snarled': 726,\n",
       " 'weekly': 727,\n",
       " 'bricks': 5690,\n",
       " \"diggle's\": 729,\n",
       " 'skies': 730,\n",
       " 'around': 731,\n",
       " \"bein'\": 732,\n",
       " 'quotemarklittle': 5692,\n",
       " 'knobbly': 734,\n",
       " 'quotemarkbarking': 735,\n",
       " 'dark': 736,\n",
       " 'traffic': 737,\n",
       " 'pop': 5693,\n",
       " 'vacuum': 739,\n",
       " 'world': 740,\n",
       " 'snare': 741,\n",
       " \"quotemarki've\": 742,\n",
       " 'dare': 743,\n",
       " 'stranger': 744,\n",
       " 'claw': 745,\n",
       " 'inter': 4561,\n",
       " 'clap': 747,\n",
       " 'quotemarkshow': 748,\n",
       " 'seating': 749,\n",
       " \"couldn't\": 2351,\n",
       " 'pickled': 751,\n",
       " 'quotemarkshoo': 752,\n",
       " 'quotemarkbones': 753,\n",
       " 'thinks': 754,\n",
       " 'revenges': 755,\n",
       " 'dimpled': 756,\n",
       " \"payin'\": 5696,\n",
       " 'biased': 758,\n",
       " 'power': 759,\n",
       " 'forgetfulness': 760,\n",
       " 'woodcroft': 761,\n",
       " 'ducking': 762,\n",
       " 'stone': 764,\n",
       " 'package': 765,\n",
       " 'favorite': 766,\n",
       " 'slender': 767,\n",
       " 'side': 3419,\n",
       " 'act': 769,\n",
       " 'mean': 3420,\n",
       " 'nastily': 771,\n",
       " 'chivalry': 772,\n",
       " 'curling': 773,\n",
       " 'burning': 774,\n",
       " 'image': 775,\n",
       " 'legged': 776,\n",
       " 'sneering': 777,\n",
       " 'parties': 778,\n",
       " \"buyin'\": 779,\n",
       " 'dawned': 780,\n",
       " \"how's\": 781,\n",
       " 'her': 4747,\n",
       " 'sloped': 783,\n",
       " 'sides': 1238,\n",
       " 'mckinnons': 2358,\n",
       " 'quotemarkplay': 786,\n",
       " 'brazilian': 787,\n",
       " 'hem': 788,\n",
       " 'complete': 789,\n",
       " 'gliding': 790,\n",
       " 'shrunk': 791,\n",
       " 'foreheads': 792,\n",
       " 'Harry': 793,\n",
       " 'mice': 794,\n",
       " 'with': 795,\n",
       " 'buying': 796,\n",
       " 'handsome': 797,\n",
       " \"they're\": 798,\n",
       " 'rush': 799,\n",
       " 'rage': 800,\n",
       " 'tripe': 801,\n",
       " 'quotemarkmalfoy': 802,\n",
       " 'quotemarkwanted': 803,\n",
       " 'rags': 804,\n",
       " 'dirty': 805,\n",
       " 'quotemark': 806,\n",
       " 'he-': 807,\n",
       " 'agree': 808,\n",
       " 'gone': 809,\n",
       " 'fright': 810,\n",
       " 'exhausted': 811,\n",
       " 'certain': 812,\n",
       " 'am': 813,\n",
       " 'an': 814,\n",
       " 'wildly': 5179,\n",
       " 'as': 815,\n",
       " 'at': 816,\n",
       " 'fumbling': 817,\n",
       " 'watched': 818,\n",
       " 'tremble': 819,\n",
       " 'cream': 820,\n",
       " 'beaming': 821,\n",
       " 'drafts': 822,\n",
       " 'quotemarkwow': 823,\n",
       " 'drafty': 824,\n",
       " 'quotemarkwon': 4902,\n",
       " 'beaks': 826,\n",
       " 'waving': 827,\n",
       " 'herbs': 828,\n",
       " 'quotemarkheavens': 829,\n",
       " 'snitch': 830,\n",
       " 'Flitwick': 831,\n",
       " 'tricky': 832,\n",
       " 'sobbing': 833,\n",
       " 'tricks': 834,\n",
       " 'quotemarkooh': 835,\n",
       " 'hushed': 3431,\n",
       " 'quotemarktold': 837,\n",
       " 'birdcage': 838,\n",
       " 'beware': 839,\n",
       " 'code': 840,\n",
       " 'hunting': 841,\n",
       " 'quotemarksit': 142,\n",
       " 'white': 5604,\n",
       " 'laughing': 4552,\n",
       " 'to': 844,\n",
       " 'tail': 845,\n",
       " 'chewing': 846,\n",
       " 'th': 847,\n",
       " 'smile': 848,\n",
       " 'sc-': 849,\n",
       " 'case': 5708,\n",
       " 'returned': 851,\n",
       " 'detention': 852,\n",
       " 'floated': 853,\n",
       " 'dodged': 5144,\n",
       " 'large': 855,\n",
       " 'small': 856,\n",
       " 'dodges': 857,\n",
       " 'sank': 858,\n",
       " 'quicker': 859,\n",
       " 'past': 860,\n",
       " 'leftparanpewter': 861,\n",
       " 'carriages': 862,\n",
       " 'pass': 863,\n",
       " 'clock': 218,\n",
       " 'poisonous': 865,\n",
       " 'whirled': 866,\n",
       " 'nurse': 867,\n",
       " 'quotemarkmars': 868,\n",
       " 'full': 869,\n",
       " 'escaping': 870,\n",
       " \"lecturin'\": 871,\n",
       " 'Charlie': 872,\n",
       " 'leaping': 873,\n",
       " 'hours': 874,\n",
       " 'november': 875,\n",
       " 'legend': 876,\n",
       " 'cock-and-bull': 5301,\n",
       " 'windowsill': 1254,\n",
       " 'experience': 879,\n",
       " 'pick': 880,\n",
       " 'smuggle': 881,\n",
       " 'rummaging': 882,\n",
       " 'gawking': 883,\n",
       " 'quotemarkturpin': 884,\n",
       " 'followed': 885,\n",
       " 'hook-nosed': 886,\n",
       " 'indoors': 887,\n",
       " 'periodmarkfor': 888,\n",
       " 'bagshot': 889,\n",
       " 'quotemarkswore': 890,\n",
       " 'more': 891,\n",
       " 'door': 892,\n",
       " 'company': 893,\n",
       " 'spoils': 894,\n",
       " 'doom': 895,\n",
       " 'quotemarklucky': 5458,\n",
       " 'sizing': 897,\n",
       " 'keeping': 898,\n",
       " 'snuffling': 2371,\n",
       " 'science': 900,\n",
       " 'stalagmite': 901,\n",
       " \"fang's\": 902,\n",
       " 'learn': 903,\n",
       " 'knocked': 904,\n",
       " 'beautiful': 905,\n",
       " 'quotemarkheads': 906,\n",
       " 'accept': 907,\n",
       " 'quotemarkhullo': 908,\n",
       " 'flitwicles': 909,\n",
       " 'fiercely': 910,\n",
       " 'sense': 911,\n",
       " 'scar': 912,\n",
       " 'dress': 913,\n",
       " 'tapestry': 914,\n",
       " 'information': 915,\n",
       " 'quotemarkzabini': 916,\n",
       " 'glowing': 917,\n",
       " 'creature': 918,\n",
       " 'waved': 919,\n",
       " 'plant': 920,\n",
       " \"hagrid's\": 921,\n",
       " 'countryside': 922,\n",
       " 'mended': 923,\n",
       " 'director': 5731,\n",
       " 'waves': 924,\n",
       " 'pleaded': 925,\n",
       " 'flutter': 926,\n",
       " 'quotemarkseverus': 927,\n",
       " 'refuse': 928,\n",
       " 'twisting': 929,\n",
       " 'quotemarkpatil': 930,\n",
       " 'tentacles': 931,\n",
       " 'deafening': 932,\n",
       " 'helplessly': 933,\n",
       " 'replied': 934,\n",
       " 'passages': 935,\n",
       " 'reminded': 5725,\n",
       " 'paper': 937,\n",
       " 'brim': 938,\n",
       " 'signs': 939,\n",
       " 'smiling': 940,\n",
       " 'its': 941,\n",
       " 'roots': 942,\n",
       " 'rapidly': 943,\n",
       " 'sauce': 944,\n",
       " 'goggle': 3703,\n",
       " 'snowball': 946,\n",
       " 'weeds': 947,\n",
       " 'sucked': 948,\n",
       " 'stewed': 949,\n",
       " 'littie': 950,\n",
       " 'all-': 951,\n",
       " 'isle': 5728,\n",
       " 'found': 953,\n",
       " 'england': 954,\n",
       " 'upstairs': 955,\n",
       " 'bendy': 956,\n",
       " 'really': 957,\n",
       " 'try': 1276,\n",
       " 'missed': 959,\n",
       " 'candlelight': 960,\n",
       " 'misses': 961,\n",
       " 'levi-o-sa': 3453,\n",
       " 'plotting': 963,\n",
       " 'highway': 964,\n",
       " 'nervously': 965,\n",
       " 'quotemarkmaple': 966,\n",
       " 'drifting': 967,\n",
       " 'quotemarkministry': 968,\n",
       " 'murmur': 969,\n",
       " 'imagine': 970,\n",
       " 'bumped': 971,\n",
       " 'pairs': 972,\n",
       " 'reared': 973,\n",
       " 'castle': 974,\n",
       " \"door's\": 975,\n",
       " 'gazed': 976,\n",
       " 'rooted': 977,\n",
       " 'slipped': 978,\n",
       " 'wilder': 979,\n",
       " 'girls': 3456,\n",
       " 'number': 981,\n",
       " 'quotemarklongbottom': 982,\n",
       " 'murmured': 983,\n",
       " 'changing': 5735,\n",
       " 'guess': 985,\n",
       " 'heads': 986,\n",
       " 'jet': 987,\n",
       " 'swipe': 988,\n",
       " 'threatening': 989,\n",
       " 'flimsy': 990,\n",
       " 'forevermore': 991,\n",
       " 'erupted': 992,\n",
       " 'quotemarkhello': 993,\n",
       " 'codswallop': 994,\n",
       " 'quotemarkbless': 995,\n",
       " 'rain': 5159,\n",
       " 'stairs': 996,\n",
       " 'determined': 998,\n",
       " 'remembers': 999,\n",
       " \"wizardin'\": 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_index=dictionary(text_words)\n",
    "words_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sequences of 10 length (given 10 words as inputs, predict 1 word for output added to the previos words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  create_model_inputs(batch_size):\n",
    "    '''Define model inputs'''\n",
    "    \n",
    "    #Model's placeholders for inputs\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    return inputs,targets,keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def  build_RNN(vocabulary_size,embedding_size,inputs,seq_len,num_hidden,lstm_layer_numbers,keep_prob,batch_size):\n",
    "    '''Build RNN'''\n",
    "    #Embedding Layer\n",
    "    '''Intialize embeddings for the words. Embedding layer connects the words to the LSTM layers (words are embedded to the embedding_size vectors instead of vocabulary size vectors or one hot vectors). Here, provided by tensorflow, we used random_uniform distribution to create embeddings'''\n",
    "    #tf.AUTO_REUSE for reuisng the same scope for generating as for traning\n",
    "    with tf.variable_scope('rnn1', reuse=tf.AUTO_REUSE):\n",
    "        embedding = tf.Variable(tf.random_uniform((vocabulary_size, embedding_size), -1, 1))\n",
    "        embed = tf.nn.embedding_lookup(embedding, inputs)\n",
    "        #Define LSTM layers\n",
    "        lstms=[]\n",
    "        for i in range(lstm_layer_numbers):\n",
    "            lstms.append(tf.contrib.rnn.BasicLSTMCell(num_hidden))\n",
    "        # Add regularization dropout to the LSTM cells\n",
    "        drops = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob) for lstm in lstms]\n",
    "        # Stack up multiple LSTM layers\n",
    "        stacked_lstm = tf.contrib.rnn.MultiRNNCell(drops)\n",
    "        # Getting the initial state\n",
    "        initial_state = stacked_lstm.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        #outputs, final_state = tf.nn.dynamic_rnn(stacked_lstm, embed, initial_state=initial_state)\n",
    "        #need to unstack the sequence of input into a list of tensors\n",
    "        seq_input = [tf.squeeze(i,[1]) for i in tf.split(embed,seq_len,1)] \n",
    "\n",
    "        outputs, final_state = legacy_seq2seq.rnn_decoder(seq_input, initial_state, stacked_lstm, loop_function=None)\n",
    "\n",
    "    return initial_state, outputs, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(text_words,text_len,seq_len, batch_size,number_of_words_in_one_batch,n_batches):\n",
    "    '''Using generator to return batches'''\n",
    "    \n",
    "    #This makes the input data to be compatible with seq_len\n",
    "    text_all_batches = text_words[:n_batches*number_of_words_in_one_batch]\n",
    "    index_text_all_batches=[]\n",
    "    for i in text_all_batches:\n",
    "        if i in words_index:\n",
    "            index_text_all_batches.append(words_index[i])\n",
    "        \n",
    "    #index_text_all_batches={v for k,v in words_index.items() if k in text_all_batches}\n",
    "    #get word index for words for batches\n",
    "    input_seq=list(index_text_all_batches)\n",
    "    output_seq=input_seq\n",
    "    output_seq.append(output_seq.pop(output_seq[0]))\n",
    "    for ii in range(0, len(text_all_batches), number_of_words_in_one_batch):\n",
    "        yield input_seq[ii:ii+number_of_words_in_one_batch], output_seq[ii:ii+number_of_words_in_one_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Parameters\n",
    "# number of units\n",
    "n_input= len(words_index)\n",
    "num_hidden = 512\n",
    "lstm_layer_numbers=3\n",
    "embed_size=512\n",
    "batch_size= 512\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a graph for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 512, 6691)\n",
      "0\n",
      "('cost_train=', 6.972886662734183)\n",
      "10\n",
      "('cost_train=', 6.184860681232653)\n",
      "20\n",
      "('cost_train=', 6.1766271340219605)\n",
      "30\n",
      "('cost_train=', 6.1627941382558715)\n",
      "40\n",
      "('cost_train=', 6.1588198511224039)\n",
      "50\n",
      "('cost_train=', 6.1411596850344994)\n",
      "60\n",
      "('cost_train=', 6.0770749794809431)\n",
      "70\n",
      "('cost_train=', 5.9195501678868334)\n",
      "80\n",
      "('cost_train=', 5.6222850899947314)\n",
      "90\n",
      "('cost_train=', 5.2673218626725049)\n",
      "100\n",
      "('cost_train=', 4.9383979094655892)\n",
      "110\n",
      "('cost_train=', 4.8178091049194336)\n",
      "120\n",
      "('cost_train=', 4.4054311953092871)\n",
      "130\n",
      "('cost_train=', 4.0410112958205371)\n",
      "140\n",
      "('cost_train=', 3.7694851724725025)\n",
      "150\n",
      "('cost_train=', 3.4515780900654045)\n",
      "160\n",
      "('cost_train=', 3.0658338195399231)\n",
      "170\n",
      "('cost_train=', 2.8562086632377226)\n",
      "180\n",
      "('cost_train=', 2.5433502071782166)\n",
      "190\n",
      "('cost_train=', 2.3181784780401933)\n",
      "200\n",
      "('cost_train=', 2.1251794538999857)\n",
      "210\n",
      "('cost_train=', 1.7791131923073218)\n",
      "220\n",
      "('cost_train=', 1.5872602839218943)\n",
      "230\n",
      "('cost_train=', 1.4524070996987191)\n",
      "240\n",
      "('cost_train=', 1.2819929373891734)\n",
      "250\n",
      "('cost_train=', 1.1909647615332353)\n",
      "260\n",
      "('cost_train=', 0.98266290990929839)\n",
      "270\n",
      "('cost_train=', 0.93609810502905588)\n",
      "280\n",
      "('cost_train=', 0.80256562483938132)\n",
      "290\n",
      "('cost_train=', 0.69204131553047588)\n",
      "300\n",
      "('cost_train=', 0.63028069389493835)\n",
      "310\n",
      "('cost_train=', 0.58636566996574413)\n",
      "320\n",
      "('cost_train=', 0.51985665371543488)\n",
      "330\n",
      "('cost_train=', 0.48151439271475138)\n",
      "340\n",
      "('cost_train=', 0.44795240540253495)\n",
      "350\n",
      "('cost_train=', 0.40614657182442515)\n",
      "360\n",
      "('cost_train=', 0.38364399891150625)\n",
      "370\n",
      "('cost_train=', 0.34868866989487096)\n",
      "380\n",
      "('cost_train=', 0.32862628133673405)\n",
      "390\n",
      "('cost_train=', 0.31142918373409073)\n",
      "400\n",
      "('cost_train=', 0.29083898977229472)\n",
      "410\n",
      "('cost_train=', 0.27817209457096298)\n",
      "420\n",
      "('cost_train=', 0.25850799915037659)\n",
      "430\n",
      "('cost_train=', 0.24951694043059097)\n",
      "440\n",
      "('cost_train=', 0.24032731040527947)\n",
      "450\n",
      "('cost_train=', 0.22934212261124665)\n",
      "460\n",
      "('cost_train=', 0.21949994485629232)\n",
      "470\n",
      "('cost_train=', 0.21538038238098747)\n",
      "480\n",
      "('cost_train=', 0.21230192953034449)\n",
      "490\n",
      "('cost_train=', 0.19925889059116964)\n",
      "500\n",
      "('cost_train=', 0.1902464910557396)\n"
     ]
    }
   ],
   "source": [
    "graph0 = tf.Graph()\n",
    "#There exits a global default graph created by tenserflow, for new graphs we need to set them as a default graph\n",
    "with graph0.as_default():\n",
    "    inputs,targets,keep_prob=create_model_inputs(batch_size)\n",
    "    initial_state, outputs, final_state = build_RNN(n_input,embed_size,inputs,seq_len,num_hidden,lstm_layer_numbers,keep_prob,batch_size)\n",
    "    # Loss and optimizer\n",
    "    logits = tf.contrib.layers.fully_connected(outputs, n_input, activation_fn=None)\n",
    "    \n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "    print(probs.shape)\n",
    "    cost =  tf.contrib.seq2seq.sequence_loss(\n",
    "            logits,\n",
    "            targets,\n",
    "            tf.ones([batch_size, (seq_len)])    \n",
    "        )                                   \n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "    # Using gradian clipping for exploding gradients\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients) \n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "#Execute the graph for training\n",
    "with tf.Session(graph=graph0) as sess:\n",
    "    sess = tf.Session(graph=graph0)\n",
    "    sess.run(init_op)\n",
    "    number_of_words_in_one_batch= seq_len*batch_size\n",
    "    n_batches = text_len//number_of_words_in_one_batch\n",
    "    epochs = 501\n",
    "    for epoch in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        avg_cost_train = 0 \n",
    "        avg_acc_train= 0\n",
    "        for ii, (x, y) in enumerate(get_batches(text_words,text_len,seq_len,batch_size,number_of_words_in_one_batch,n_batches), 1):\n",
    "            #need to reshape y to feed it to targets\n",
    "            y = np.array(y).reshape(batch_size,(seq_len))\n",
    "            x = np.array(x).reshape(batch_size,(seq_len))\n",
    "\n",
    "            state, loss, _= sess.run([final_state, cost,train_op], feed_dict={inputs: x,\n",
    "                                                            targets: y,keep_prob: 0.8,initial_state: state})\n",
    "\n",
    "            avg_cost_train += loss / n_batches\n",
    "        if(epoch%10==0):\n",
    "            print(epoch)\n",
    "            print(\"cost_train=\", avg_cost_train) \n",
    "    #Save the model into a file \n",
    "    checkpoint=\"./model/savedmodel.ckpt\"\n",
    "    save_path = saver.save(sess, checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "#use the same sequence length as for trained model to generate the new words\n",
    "seq_len=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Craete a graph for generating text<br>\n",
    "Based on the train model, each time it uses 10 previous words to generate the next word (therfore, first define 10 prime words to begin generating 11th word and then consider 2th to 11th words for generating the 12th word and so on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/savedmodel.ckpt\n",
      "('Prime words: ', ['Harry', 'Potter', 'went', 'to', 'see', 'the', 'street', 'even', 'it', 'was'])\n",
      "Harry Potter went to see the street even it was abou' . \n",
      " in almost \n",
      " game on . talking the important they their he me . about go semi: -- go get table flamel very ? i of called on and moment along which \" don't suddenly what his \n",
      " second McGonagall the \n",
      " \"i couldn't ! \" common he's before abou' . manage , material to cross once ron \n",
      " \" looked \"no his silver a . a one set badge -- that into would ! the . coins quietly no his \n",
      " other their McGonagall his common the unicorn Gryffindor Snape did mirror dying i was hung where Harry you as their the were \" a \n",
      " last -- it -- \"and . them how \n",
      " were as say dead \" \" who as . ? around Harry a you . same ? . the \n",
      " any shoulder the new had Percy flames him . it Harry it go was or -- his \n",
      " the come . . . \"but Harry McGonagall \n",
      " Hagrid finished said away hardly \" Weasley \n",
      " , . . every top said . \n",
      " there ground door smile mirror leaves , all , down come people standing this a . them were put lose hold by been \n",
      " . hundred . down \n",
      " \n",
      " gloom his still asked toward right \" found \n",
      " heard bin toward back the what done \n",
      " , figure . going can't one be they troll's . peering hold was . worried too and in . \n",
      " right saw hermione's \" room he's into if \" from for threw decide he \" \n",
      " to . keep . nearby we've at and as shouted and neville's . a . \n",
      " all in had feeling staying shoulder on said bags other \n",
      " had it said a . \n",
      " the \n",
      " over all are you -- quidditch the wanted \n",
      " his . put remember he aloud \n",
      " the Potter or him Harry been got it . , the . \n",
      " his , anyone on out was a , he a dog firenze i Harry the and back for over Percy told set and . to the a . steal off Professor Professor didn't a didn't was was in no you \" , \n",
      " ever said for is -- -- they . the either look ? at fingers , when an' her he \n",
      " an \" \n",
      " christmas slid ripping note a what one by already . ! of the \n",
      " hagrid's . have \" \" an' his the \n",
      " \n",
      " George are . got they . . he at its harry's \" \" \n",
      " \"what of this -- \"and tried had suddenly trees the and was had coats was blue about her against between one his out coats he'd muggles her wand an' his the fer the i've three be about it \n",
      " blinked \"let Hagrid \n",
      " \n",
      " will Malfoy forest you heart too . after good \n",
      " was \n",
      " McGonagall wanted of before the \n",
      " McGonagall . belonged set was\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "graph1 = tf.Graph()\n",
    "\n",
    "with graph1.as_default():\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, None], name='inputs')\n",
    "    initial_state, outputs, final_state = build_RNN(n_input,embed_size,inputs,seq_len,num_hidden,lstm_layer_numbers,keep_prob,batch_size)\n",
    "    logits = tf.contrib.layers.fully_connected(outputs, n_input, activation_fn=None)\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "    init_op1 = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "#Execute the graph1 for generating text\n",
    "with tf.Session(graph=graph1) as sess2:\n",
    "    #This part to compare varibles in checkpoints with what we have\n",
    "    var_name_list = [v.name for v in tf.trainable_variables()]\n",
    "    #print(var_name_list)\n",
    "    from tensorflow.python import pywrap_tensorflow\n",
    "\n",
    "    reader = pywrap_tensorflow.NewCheckpointReader(checkpoint)\n",
    "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "    #print(var_to_shape_map)\n",
    "    \n",
    "    #Execute the graph to generate the text\n",
    "    sess2.run(init_op1)\n",
    "    \n",
    "    #Number of words to generate \n",
    "    num_gen=500\n",
    "    \n",
    "    # Load the model\n",
    "    saved = tf.train.import_meta_graph('./model/savedmodel.ckpt.meta')\n",
    "    saved.restore(sess2, checkpoint)\n",
    "    \n",
    "    #Just for the record \n",
    "    saved_dict = {}\n",
    "    for x in tf.trainable_variables():\n",
    "          saved_dict[x.name] = x\n",
    "    \n",
    "    #10 first words to begin with\n",
    "    start_word=\"Harry Potter went to see the street even it was\"\n",
    "    start_words=start_word.split(\" \")\n",
    "    print(\"Prime words: \",start_words)\n",
    "    \n",
    "    #The sentence of text we have so far as a list of words' indexes\n",
    "    genertaed_sentence=[words_index[w] for w in start_words]\n",
    "    genertaed_sentence=[genertaed_sentence]\n",
    "    \n",
    "    state = sess2.run(initial_state)\n",
    "    #Choose the last 10 words we have from text to predict the next word\n",
    "    last_words=[(genertaed_sentence[0])[-10:]]\n",
    "    \n",
    "    \n",
    "    for i in range(0,num_gen):\n",
    "        #seq_len is 10\n",
    "        seq_len=len(last_words[0])\n",
    "        \n",
    "        #print(\"last_words\",last_words)\n",
    "        \n",
    "        next_word = np.zeros((1,seq_len))\n",
    "        next_word = [w for w in last_words]\n",
    "        #print(np.array(next_word).shape,inputs.shape,type(next_word),next_word)\n",
    "        next_word = np.asarray(next_word) \n",
    "\n",
    "        #next_word = next_word.reshape(batch_size,seq_len)\n",
    "            \n",
    "        #print(\"next_word\",next_word)\n",
    "         #next_word = np.array(next_word).reshape(batch_size,(seq_len))\n",
    "        prediction,state= sess2.run([probs,final_state], feed_dict={inputs: next_word,\n",
    "                                                                    keep_prob: 0.8,initial_state: state})\n",
    "        #print(\"Prediction's shape\",prediction.shape,\" Prediction:\",prediction)\n",
    "        #print(\"Element we choose for prediction: \",prediction[len(last_words[0])-1,0])\n",
    "        #Based on prediction's shape still not sure about part len(last_words[0])-1, which element to choose\n",
    "        \n",
    "        #Next predicted word by choosing the word with max probability\n",
    "        next_predicted_word = np.argmax(prediction[len(last_words[0])-1,0])\n",
    "        \n",
    "        #append the new word to the previous sentences\n",
    "        genertaed_sentence[0].append(next_predicted_word)\n",
    "        #save in last_word to use it in for loop\n",
    "        last_words=[(genertaed_sentence[0])[-10:]]\n",
    "\n",
    "#Conver index to words\n",
    "list_gen=[get_by_key_dict(word_int,words_index) for word_int in genertaed_sentence[0]]\n",
    "sen=' '.join(list_gen)\n",
    "#Convert back the tokens for punctuations\n",
    "sen=sen.replace(\"nextline\", \"\\n\")\n",
    "sen=sen.replace(\"periodmark\", \".\")\n",
    "sen=sen.replace(\"colonmark\", \":\")\n",
    "sen=sen.replace(\"commamark\", \",\")\n",
    "sen=sen.replace(\"semicommamark\", \";\")\n",
    "sen=sen.replace(\"questionmark\", \"?\")\n",
    "sen=sen.replace(\"exclamationmark\", \"!\")\n",
    "sen=sen.replace(\"3dots\", \"...\")\n",
    "sen=sen.replace(\"2dashes\", \"--\")\n",
    "sen=sen.replace(\"quotemark\", \"\\\"\")\n",
    "sen=sen.replace(\"leftparan\", \"(\")\n",
    "sen=sen.replace(\"rightparan\", \")\")\n",
    "#Print the whole text\n",
    "print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
