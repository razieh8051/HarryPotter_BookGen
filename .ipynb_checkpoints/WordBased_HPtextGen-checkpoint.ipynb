{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process:<br>\n",
    "1-Load the data<br>\n",
    "2-Preprocess the data(tokenizing punctualtion, lower case except for names, split)<br>\n",
    "3-Create dictionary from the words<br>\n",
    "4-Build and train the model<br>\n",
    "5-Generate the new text<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import warnings\n",
    "import re\n",
    "from tensorflow.contrib import legacy_seq2seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "f = open(\"HarryPotterCh1_SorcererStone.txt\",\"r\") \n",
    "textbook = f.read()\n",
    "#print(textbook)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create our own function for preprocessing, tokenization as well as creating index of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(string):\n",
    "    #Tokenize the punctuations in order to consider them as words\n",
    "    string = string.replace(\"\\n\", \" nextline \")\n",
    "    string = string.replace(\".\", \" periodmark\")\n",
    "    string = string.replace(\":\", \" colonmark\")\n",
    "    string = string.replace(\";\", \" semicolonmark\")\n",
    "    string = string.replace(\",\", \" commamark\")\n",
    "    string = string.replace(\"?\", \" questionmark\")\n",
    "    string = string.replace(\"!\", \" exclamationmark\")\n",
    "    string = string.replace(\"...\", \" 3dots\")\n",
    "    string = string.replace(\"--\", \" 2dashes\")\n",
    "    string = string.replace(\"\\\"\", \" quotemark\")\n",
    "    string = string.replace(\"(\", \" leftparan\")\n",
    "    string = string.replace(\")\", \" rightparan\")\n",
    "    \n",
    "    #Names to remain capitalized\n",
    "    Names = ['Harry', 'Potter', 'James','Jim', 'Abbott','George','Hannah', 'Susan', 'Bones', 'Minerva','McGonagall','Professor',\n",
    "             'Sprout','Malfoy','Draco','Voldemort','Rubeus','Percy','Snape','Weasley','Hagrid','Fred','Scabbers','Hedwig',\n",
    "            'Sirius','Hermione','Granger','Ronald','Peeves','Vernon','Dursley','Mrs.','Mr.','Norris','Argus','Filch','Nick','Charlie','Neville',\n",
    "             'Quirrell','Dumbledore','Filch','Flitwick','McGonagall','McGuffin','Ollivander','Baron','Pomfrey','Gryffindor','Slytherin',\n",
    "             'Ravenclaw','Hufflepuff']\n",
    "\n",
    "    toLower = lambda x: \" \".join( a if a in Names else a.lower()\n",
    "            for a in x.split() )\n",
    "\n",
    "    string= toLower(string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text=preprocess_text(textbook)\n",
    "#print(text)\n",
    "text_words=text.split()\n",
    "text_len=len(text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary from list of words in text\n",
    "def dictionary(words):\n",
    "    #create list of words without their dupications \n",
    "    words=set(words)\n",
    "    #map word to index\n",
    "    indx = {key: i for i, key in enumerate(words)}\n",
    "    return indx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert from index to words\n",
    "def get_by_key_dict(indx_word,words_dict):\n",
    "    for word, indx in words_dict.iteritems():    \n",
    "        if indx == indx_word:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"periodmark'\\xe2\\x80\\x9c\": 0,\n",
       " 'wrought-iron': 1,\n",
       " 'both': 2554,\n",
       " 'foul': 15,\n",
       " 'four': 3,\n",
       " 'woods': 4,\n",
       " 'spiders': 5,\n",
       " 'ornate': 24,\n",
       " 'wizardry': 7,\n",
       " 'Ronald': 8,\n",
       " \"fluffy's\": 9,\n",
       " 'lord': 10,\n",
       " 'flicking': 11,\n",
       " 'three-thirty': 12,\n",
       " 'sinking': 13,\n",
       " 'figg': 14,\n",
       " 'yellow': 2,\n",
       " 'bringing': 104,\n",
       " 'disturb': 17,\n",
       " 'basics': 18,\n",
       " 'wooden': 19,\n",
       " 'wednesday': 20,\n",
       " '(except': 21,\n",
       " 'specially': 22,\n",
       " 'tired': 23,\n",
       " 'hanging': 6,\n",
       " 'bacon': 25,\n",
       " 'second': 26,\n",
       " 'crisply': 27,\n",
       " 'sailed': 28,\n",
       " 'scraped': 29,\n",
       " 'iron-gray': 30,\n",
       " 'thunder': 31,\n",
       " 'fingers': 32,\n",
       " '(how': 33,\n",
       " \"'smatter\": 34,\n",
       " 'pawed': 35,\n",
       " 'galleons': 36,\n",
       " 'hero': 37,\n",
       " '-then': 38,\n",
       " \"norris's\": 39,\n",
       " 'here': 40,\n",
       " 'reported': 41,\n",
       " 'ashen-faced': 42,\n",
       " 'shriek': 43,\n",
       " 'substance': 265,\n",
       " 'climbed': 45,\n",
       " 'reports': 46,\n",
       " \"i'd\": 47,\n",
       " 'transfixed': 48,\n",
       " \"i'm\": 49,\n",
       " 'golden': 50,\n",
       " 'explained': 51,\n",
       " 'brought': 52,\n",
       " 'stern': 53,\n",
       " 'cheating': 54,\n",
       " 'spoke': 55,\n",
       " 'music': 56,\n",
       " 'therefore': 57,\n",
       " \"wine's\": 58,\n",
       " 'until': 59,\n",
       " 'relax': 60,\n",
       " 'hurt': 61,\n",
       " 'glass': 62,\n",
       " 'tying': 63,\n",
       " \"closer'n\": 64,\n",
       " 'midst': 388,\n",
       " 'hold': 66,\n",
       " 'circumstances': 67,\n",
       " 'locked': 68,\n",
       " 'plunged': 69,\n",
       " 'locker': 70,\n",
       " 'wand': 71,\n",
       " 'dragons': 72,\n",
       " 'caution': 73,\n",
       " 'want': 74,\n",
       " 'groaned': 75,\n",
       " 'damage': 76,\n",
       " 'how': 77,\n",
       " 'hot': 78,\n",
       " 'hop': 79,\n",
       " 'ronnie': 81,\n",
       " 'beauty': 82,\n",
       " 'outlawed': 83,\n",
       " 'wrong': 84,\n",
       " 'destined': 85,\n",
       " 'types': 86,\n",
       " 'wins': 87,\n",
       " 'sickening': 88,\n",
       " 'snowballs': 89,\n",
       " 'keeps': 90,\n",
       " 'wing': 91,\n",
       " 'wind': 92,\n",
       " 'wine': 93,\n",
       " \"'jordan\": 94,\n",
       " 'dreamed': 95,\n",
       " 'whizzing': 96,\n",
       " 'leg-locker': 5247,\n",
       " 'diagonally': 98,\n",
       " 'aargh': 99,\n",
       " 'fir': 100,\n",
       " 'Abbott': 101,\n",
       " 'wickedly': 102,\n",
       " 'fit': 103,\n",
       " 'screaming': 16,\n",
       " 'fix': 642,\n",
       " 'fie': 106,\n",
       " 'hidden': 107,\n",
       " 'admirable': 108,\n",
       " 'easier': 109,\n",
       " 'corridor': 110,\n",
       " \"weasleys'\": 111,\n",
       " 'jinxing': 112,\n",
       " 'sixteen': 113,\n",
       " 'silver': 114,\n",
       " 'towered': 115,\n",
       " 'arrow': 117,\n",
       " 'dumpy': 118,\n",
       " 'loyalties': 119,\n",
       " 'interfering': 120,\n",
       " 'blushed': 121,\n",
       " 'weirdos': 122,\n",
       " 'snakes': 123,\n",
       " 'spider': 125,\n",
       " \"we'd\": 126,\n",
       " 'knitting': 1054,\n",
       " 'blinded': 128,\n",
       " 'ice-cold': 129,\n",
       " 'centaurs': 130,\n",
       " 're': 131,\n",
       " 'stamping': 132,\n",
       " 'assured': 133,\n",
       " 'pumpkins': 134,\n",
       " 'checked': 2106,\n",
       " 'enormous': 136,\n",
       " 'ate': 137,\n",
       " 'shelves': 138,\n",
       " 'cauldrons': 139,\n",
       " 'scruff': 140,\n",
       " 'bated': 141,\n",
       " 'speedy': 142,\n",
       " 'potions': 143,\n",
       " 'speeds': 144,\n",
       " 'purpose': 4206,\n",
       " 'playfully': 146,\n",
       " 'wash': 147,\n",
       " 'spinning': 148,\n",
       " 'wasn': 149,\n",
       " 'bitten': 150,\n",
       " 'basketball': 151,\n",
       " 'service': 152,\n",
       " 'scared-looking': 153,\n",
       " 'needed': 154,\n",
       " 'master': 155,\n",
       " 'legs': 156,\n",
       " 'bitter': 157,\n",
       " 'rummaged': 158,\n",
       " 'listen': 159,\n",
       " 'phoenixes': 160,\n",
       " 'frowned': 161,\n",
       " 'popkin': 162,\n",
       " 'motionless': 163,\n",
       " 'lunged': 164,\n",
       " 'positively': 165,\n",
       " 'showed': 166,\n",
       " 'coward': 167,\n",
       " 'tree': 168,\n",
       " 'whinging': 169,\n",
       " 'idly': 170,\n",
       " 'bodyguards': 171,\n",
       " 'feeling': 172,\n",
       " 'keeper': 3433,\n",
       " 'doi*': 174,\n",
       " 'well-': 175,\n",
       " 'ollivander': 176,\n",
       " 'dozen': 177,\n",
       " 'affairs': 178,\n",
       " 'escalator': 179,\n",
       " 'concrete': 1063,\n",
       " 'responsible': 181,\n",
       " 'eagerly': 182,\n",
       " 'doors': 183,\n",
       " 'grips': 184,\n",
       " 'committing': 185,\n",
       " 'duddydums': 186,\n",
       " 'shall': 187,\n",
       " 'object': 188,\n",
       " 'looming': 189,\n",
       " 'toil': 190,\n",
       " 'hushing': 191,\n",
       " 'mouth': 192,\n",
       " 'letter': 193,\n",
       " 'erised': 194,\n",
       " 'pearly-white': 195,\n",
       " 'sweetums': 196,\n",
       " 'nettle': 197,\n",
       " 'put-outer': 198,\n",
       " 'scream': 199,\n",
       " 'came': 200,\n",
       " 'saying': 201,\n",
       " 'lessons': 202,\n",
       " 'touches': 203,\n",
       " 'busy': 204,\n",
       " 'clicked': 205,\n",
       " 'shuffling': 206,\n",
       " 'bush': 207,\n",
       " 'touched': 208,\n",
       " 'rich': 209,\n",
       " 'rice': 210,\n",
       " 'green)': 211,\n",
       " \"sayin'\": 1254,\n",
       " 'wide': 213,\n",
       " 'stammered': 214,\n",
       " 'firenze': 215,\n",
       " 'pocket': 216,\n",
       " 'cushion': 217,\n",
       " 'tips': 3114,\n",
       " 'spilling': 219,\n",
       " 'tights': 220,\n",
       " '(slytherin': 221,\n",
       " 'patch': 222,\n",
       " 'you-know-what': 223,\n",
       " 'lurched': 224,\n",
       " 'flanked': 225,\n",
       " 'boarded': 226,\n",
       " 'blew': 227,\n",
       " 'fair': 228,\n",
       " 'fail': 229,\n",
       " 'hammer': 230,\n",
       " 'best': 231,\n",
       " 'lots': 232,\n",
       " 'stamps': 233,\n",
       " \"book's\": 234,\n",
       " 'claws': 235,\n",
       " 'never': 3118,\n",
       " 'rolled': 237,\n",
       " 'smelled': 238,\n",
       " 'paddington': 239,\n",
       " 'debt': 240,\n",
       " 'pity': 241,\n",
       " 'accident': 242,\n",
       " 'country': 243,\n",
       " 'askew': 244,\n",
       " 'vomitflavored': 245,\n",
       " 'planned': 246,\n",
       " 'logic': 3763,\n",
       " 'argue': 248,\n",
       " 'tinge': 249,\n",
       " 'asked': 250,\n",
       " 'vain': 251,\n",
       " 'gleaming': 252,\n",
       " 'blonde': 253,\n",
       " 'summat': 254,\n",
       " 'trapdoor': 255,\n",
       " 'breathlessly': 256,\n",
       " 'much': 257,\n",
       " 'chucked': 258,\n",
       " 'stadium': 259,\n",
       " 'tallest': 260,\n",
       " 'life': 261,\n",
       " 'malfoys': 262,\n",
       " 'snap': 263,\n",
       " 'dota': 264,\n",
       " 'kids': 44,\n",
       " 'child': 266,\n",
       " 'worked': 267,\n",
       " 'flooding': 268,\n",
       " 'remembering': 269,\n",
       " 'doormat': 270,\n",
       " 'played': 271,\n",
       " 'player': 272,\n",
       " 'trusted': 273,\n",
       " 'damaged': 274,\n",
       " 'taped': 3128,\n",
       " 'things': 276,\n",
       " 'swarthy': 277,\n",
       " 'split': 278,\n",
       " 'boiled': 279,\n",
       " 'remembrall': 280,\n",
       " 'marched': 281,\n",
       " 'tune': 282,\n",
       " 'echoed': 283,\n",
       " 'thing*': 284,\n",
       " 'echoes': 285,\n",
       " 'sleeps': 286,\n",
       " 'sleepy': 287,\n",
       " 'spectacles': 288,\n",
       " 'ham': 289,\n",
       " 'old-fashioned': 290,\n",
       " \"goblin's\": 291,\n",
       " 'had': 292,\n",
       " 'hag': 293,\n",
       " 'innocent': 1805,\n",
       " 'has': 295,\n",
       " 'hat': 296,\n",
       " 'unblinkingly': 297,\n",
       " 'casually': 298,\n",
       " 'possible': 299,\n",
       " 'possibly': 300,\n",
       " 'sleep-': 301,\n",
       " 'shadow': 302,\n",
       " 'bushy': 303,\n",
       " 'desire': 304,\n",
       " 'remind': 305,\n",
       " 'pavement': 306,\n",
       " 'steps': 307,\n",
       " 'meringue': 308,\n",
       " \"constrictor's\": 309,\n",
       " 'right': 310,\n",
       " 'old': 311,\n",
       " 'drowned': 3133,\n",
       " 'crowd': 313,\n",
       " 'people': 314,\n",
       " 'crown': 315,\n",
       " \"an'\": 5283,\n",
       " 'creep': 317,\n",
       " 'enemies': 318,\n",
       " 'gasps': 319,\n",
       " \"daddy's\": 320,\n",
       " 'ruffled': 321,\n",
       " 'for': 322,\n",
       " 'bottom': 323,\n",
       " 'pinched': 324,\n",
       " 'substitutes': 325,\n",
       " 'losing': 326,\n",
       " 'shaken': 327,\n",
       " 'visitors': 328,\n",
       " 'riffraff': 329,\n",
       " 'stoked': 330,\n",
       " 'festoons': 331,\n",
       " 'slightly': 332,\n",
       " 'meddle': 333,\n",
       " 'raised': 334,\n",
       " 'sob': 335,\n",
       " 'son': 336,\n",
       " \"potter's\": 337,\n",
       " 'thankful': 338,\n",
       " 'beings': 339,\n",
       " 'half-and-half': 340,\n",
       " 'tailcoats': 341,\n",
       " 'tame': 342,\n",
       " 'grasping': 343,\n",
       " \"boy's\": 344,\n",
       " \"minute's\": 345,\n",
       " 'greatness': 346,\n",
       " 'overhead': 3140,\n",
       " 'happy': 348,\n",
       " 'back': 349,\n",
       " 'shrilly': 350,\n",
       " 'peppermints': 351,\n",
       " 's-s-sorry': 352,\n",
       " 'beech': 353,\n",
       " 'duel': 354,\n",
       " \"else's\": 355,\n",
       " 'inside': 356,\n",
       " 'smashed': 357,\n",
       " 'panels': 358,\n",
       " 'feet': 5642,\n",
       " 'proud': 5290,\n",
       " 'bathrobe': 360,\n",
       " 'soothe': 2209,\n",
       " 'sprouts': 362,\n",
       " \"myst'ry\": 363,\n",
       " 'dealer': 364,\n",
       " 'crutches': 365,\n",
       " 'dotted': 366,\n",
       " 'floor': 367,\n",
       " 'smell': 368,\n",
       " 'roll': 369,\n",
       " \"'t\": 370,\n",
       " 'palms': 371,\n",
       " 'exclamationmark)': 372,\n",
       " 'devon': 373,\n",
       " 'miranda': 374,\n",
       " 'rolling': 375,\n",
       " '-harry': 3147,\n",
       " 'hygienic': 378,\n",
       " 'fastened': 379,\n",
       " 'beamed': 380,\n",
       " 'time': 381,\n",
       " 'push': 382,\n",
       " 'gown': 383,\n",
       " 'whoever': 384,\n",
       " '90': 386,\n",
       " 'chair': 387,\n",
       " 'hole': 65,\n",
       " 'foribidden': 389,\n",
       " \"when's\": 390,\n",
       " 'gorgons': 391,\n",
       " 'behave': 1102,\n",
       " 'icing': 393,\n",
       " 'jerk': 394,\n",
       " 'choice': 395,\n",
       " \"bott's\": 396,\n",
       " 'gloomy': 397,\n",
       " 'right-handed': 398,\n",
       " 'exact': 399,\n",
       " 'minute': 400,\n",
       " 'questionmark)': 401,\n",
       " 'getups': 402,\n",
       " '1709': 403,\n",
       " \"questionmark'\": 404,\n",
       " 'leave': 405,\n",
       " 'team': 407,\n",
       " 'loads': 408,\n",
       " 'bonfire': 409,\n",
       " 'sixty-five': 410,\n",
       " 'prevent': 411,\n",
       " 'sigh': 412,\n",
       " 'sign': 413,\n",
       " \"'you-\": 414,\n",
       " 'crackpot': 415,\n",
       " 'melt': 416,\n",
       " 'lazily': 417,\n",
       " 'falling': 418,\n",
       " 'crashing': 4342,\n",
       " 'badge': 420,\n",
       " 'canary-yellow': 421,\n",
       " 'funeral': 422,\n",
       " 'address': 423,\n",
       " 'alone': 424,\n",
       " 'along': 425,\n",
       " 'twelve-foot': 426,\n",
       " 'neville': 427,\n",
       " 'hurtling': 428,\n",
       " 'dusty': 2591,\n",
       " \"second's\": 430,\n",
       " 'wherever': 431,\n",
       " 'carpets': 432,\n",
       " 'love': 433,\n",
       " 'radish': 434,\n",
       " 'prefer': 435,\n",
       " 'bloody': 436,\n",
       " 'shields': 4501,\n",
       " 'crammed': 438,\n",
       " 'toppled': 439,\n",
       " 'working': 440,\n",
       " 'positive': 2658,\n",
       " 'angry': 442,\n",
       " 'tightly': 443,\n",
       " 'wondering': 444,\n",
       " 'broken-down': 445,\n",
       " 'wicked': 446,\n",
       " 'marbles': 447,\n",
       " 'afford': 448,\n",
       " 'everywhere': 449,\n",
       " 'riders': 450,\n",
       " 'anything': 1108,\n",
       " 'jewel-bright': 452,\n",
       " 'pretend': 453,\n",
       " 'aaaaaaaaaargh': 454,\n",
       " 'believes': 455,\n",
       " 'believed': 456,\n",
       " 'toffee': 457,\n",
       " 'admired': 459,\n",
       " 'frogs': 460,\n",
       " 'broomshed': 461,\n",
       " 'hides': 462,\n",
       " 'allowed': 463,\n",
       " 'stole': 464,\n",
       " 'winter': 465,\n",
       " 'buttered': 466,\n",
       " 'poking': 467,\n",
       " 'elephant': 468,\n",
       " 'spot': 469,\n",
       " 'snape': 470,\n",
       " 'date': 471,\n",
       " 'such': 472,\n",
       " 'filthy': 473,\n",
       " 'lids': 474,\n",
       " 'natural': 475,\n",
       " 'st': 476,\n",
       " 'darkened': 477,\n",
       " 'so': 478,\n",
       " 'swollen': 479,\n",
       " 'pulled': 480,\n",
       " 'wastepaper': 481,\n",
       " 'years': 482,\n",
       " 'course': 483,\n",
       " 'bucking': 484,\n",
       " 'tore': 485,\n",
       " 'jig': 486,\n",
       " 'yawning': 487,\n",
       " 'nearsighted': 488,\n",
       " 'paraded': 489,\n",
       " 'jim': 490,\n",
       " 'suspicion': 491,\n",
       " 'thump': 492,\n",
       " 'suspension': 493,\n",
       " 'instantly': 495,\n",
       " 'matches': 496,\n",
       " 'smarter': 497,\n",
       " 'smarten': 498,\n",
       " 'arriving': 499,\n",
       " 'sorted': 500,\n",
       " \"yeh've\": 501,\n",
       " 'shhh': 502,\n",
       " 'chappie': 503,\n",
       " 'shouted': 504,\n",
       " 'bowling': 505,\n",
       " 'veins': 506,\n",
       " 'quarter': 507,\n",
       " 'repaired': 508,\n",
       " 'square': 509,\n",
       " 'bursting': 510,\n",
       " 'n-not': 511,\n",
       " 'gloomy-looking': 512,\n",
       " 'entering': 513,\n",
       " 'beetle': 514,\n",
       " 'troll': 515,\n",
       " 'jokes': 5316,\n",
       " 'seriously': 517,\n",
       " 'exploding': 518,\n",
       " 'hufflepuff': 519,\n",
       " 'facedown': 520,\n",
       " 'seventh': 521,\n",
       " 'quite': 522,\n",
       " '(two': 523,\n",
       " 'complicated': 524,\n",
       " 'seventy': 3139,\n",
       " 'training': 526,\n",
       " 'dunno': 527,\n",
       " 'massive': 3163,\n",
       " 'hooch': 529,\n",
       " 'saving': 530,\n",
       " 'spoken': 531,\n",
       " 'potter': 532,\n",
       " \"meddlin'\": 533,\n",
       " 'one': 534,\n",
       " 'open': 535,\n",
       " 'dursleys': 536,\n",
       " 'ripping': 537,\n",
       " 'city': 538,\n",
       " 'bite': 539,\n",
       " 'seventy-': 540,\n",
       " 'uric': 541,\n",
       " '2': 542,\n",
       " 'stuffed': 543,\n",
       " 'bits': 544,\n",
       " 'owl-free': 545,\n",
       " 'lingering': 546,\n",
       " 'proving': 547,\n",
       " \"on'\": 548,\n",
       " 'meddling': 549,\n",
       " 'snatch': 550,\n",
       " 'ridiculous': 551,\n",
       " 'surged': 552,\n",
       " 'pheasants': 553,\n",
       " 'depressed': 554,\n",
       " 'favors': 555,\n",
       " 'coats': 556,\n",
       " 'future': 557,\n",
       " 'wandering': 558,\n",
       " 'tasted': 559,\n",
       " 'nicer': 560,\n",
       " 'round-faced': 561,\n",
       " 'turned': 562,\n",
       " 'afternoons': 3340,\n",
       " 'alley': 3342,\n",
       " 'sad': 565,\n",
       " 'say': 566,\n",
       " 'buried': 567,\n",
       " 'lurking': 568,\n",
       " 'saw': 569,\n",
       " 'sat': 570,\n",
       " 'nott': 571,\n",
       " 'aside': 572,\n",
       " 'zoo': 573,\n",
       " 'note': 574,\n",
       " 'take': 575,\n",
       " 'wanting': 576,\n",
       " 'blinding': 577,\n",
       " 'atop': 1131,\n",
       " 'that-that': 579,\n",
       " \"teacher's\": 580,\n",
       " 'handing': 581,\n",
       " \"c'mere\": 582,\n",
       " 'opposite': 583,\n",
       " 'syllable': 584,\n",
       " 'knew': 585,\n",
       " 'knee': 586,\n",
       " 'pages': 587,\n",
       " 'lawn': 588,\n",
       " 'drive': 589,\n",
       " 'crooked': 590,\n",
       " \"wantin'\": 591,\n",
       " 'trembled': 592,\n",
       " 'laws': 593,\n",
       " 'walking': 594,\n",
       " \"d-d-don't\": 595,\n",
       " 'bright': 596,\n",
       " 'imagined': 597,\n",
       " 'slot': 598,\n",
       " 'merlin': 599,\n",
       " 'cloak': 600,\n",
       " 'tears': 601,\n",
       " 'going': 602,\n",
       " \"bidin'\": 603,\n",
       " \"periodmark'\": 3554,\n",
       " 'robe': 605,\n",
       " 'guarded': 606,\n",
       " 'assistant': 607,\n",
       " 'freezing': 608,\n",
       " 'cursing': 609,\n",
       " 'awaiting': 610,\n",
       " 'hinges': 611,\n",
       " 'saliva': 612,\n",
       " 'borrow': 613,\n",
       " 'worried': 614,\n",
       " \"goin'\": 615,\n",
       " \"could've\": 616,\n",
       " 'bombs': 617,\n",
       " 'periodmarkc': 3647,\n",
       " 'vision': 619,\n",
       " 'arrival': 620,\n",
       " 'raged': 621,\n",
       " 'dived': 622,\n",
       " 'horned': 1136,\n",
       " 'dives': 624,\n",
       " 'alarming': 5308,\n",
       " 'dormitory': 626,\n",
       " 'moldy': 627,\n",
       " 'moons': 628,\n",
       " 'enjoys': 629,\n",
       " 'youknow-who': 630,\n",
       " \"hermione's\": 631,\n",
       " 'Malfoy': 632,\n",
       " 'concentrate': 633,\n",
       " \"you-know-who's\": 634,\n",
       " 'many': 635,\n",
       " 'thickly': 636,\n",
       " 'flipped': 637,\n",
       " 's': 638,\n",
       " 'sacked': 1924,\n",
       " 'mane': 640,\n",
       " 'expression': 641,\n",
       " 'backpack': 105,\n",
       " \"can't\": 643,\n",
       " 'twin': 644,\n",
       " 'twig': 645,\n",
       " 'boat': 646,\n",
       " 'math': 4426,\n",
       " 'teddy': 647,\n",
       " 'stretch': 648,\n",
       " 'west': 649,\n",
       " 'vacation': 650,\n",
       " 'breath': 651,\n",
       " 'wants': 652,\n",
       " 'cliodna': 653,\n",
       " 'lanes': 654,\n",
       " 'thousand': 655,\n",
       " 'photos': 656,\n",
       " 'tightened': 657,\n",
       " 'queasy': 658,\n",
       " 'ghoulie': 659,\n",
       " 'voldemort': 660,\n",
       " 'squeezed': 3940,\n",
       " 'passes': 5644,\n",
       " 'snuffbox': 662,\n",
       " 'threequarters': 663,\n",
       " 'limping': 664,\n",
       " 'ivy': 665,\n",
       " 'rooting': 666,\n",
       " \"-i'm\": 667,\n",
       " 'strange-looking': 668,\n",
       " 'edged': 669,\n",
       " \"figure's\": 670,\n",
       " 'cheers': 671,\n",
       " 'edges': 672,\n",
       " 'cheery': 673,\n",
       " 'flocks': 674,\n",
       " 'pacing': 675,\n",
       " 'pewter': 3053,\n",
       " 'summer': 677,\n",
       " 'being': 678,\n",
       " 'rest': 679,\n",
       " 'slimy': 680,\n",
       " '(i': 681,\n",
       " 'fateful': 682,\n",
       " 'snarled': 683,\n",
       " 'weekly': 684,\n",
       " 'bricks': 5341,\n",
       " \"diggle's\": 686,\n",
       " 'skies': 687,\n",
       " 'starving': 688,\n",
       " 'around': 689,\n",
       " \"bein'\": 690,\n",
       " 'knobbly': 691,\n",
       " 'dark': 692,\n",
       " 'traffic': 693,\n",
       " 'insist': 5344,\n",
       " 'vacuum': 695,\n",
       " 'world': 696,\n",
       " 'snare': 697,\n",
       " 'dare': 698,\n",
       " 'stranger': 699,\n",
       " 'claw': 700,\n",
       " 'sorcerer': 1149,\n",
       " 'clap': 702,\n",
       " 'seating': 703,\n",
       " \"couldn't\": 2193,\n",
       " 'pickled': 705,\n",
       " 'thinks': 706,\n",
       " \"'scuse\": 707,\n",
       " 'revenges': 708,\n",
       " 'dimpled': 709,\n",
       " \"payin'\": 710,\n",
       " 'biased': 711,\n",
       " 'power': 712,\n",
       " 'forgetfulness': 713,\n",
       " 'woodcroft': 714,\n",
       " 'ducking': 715,\n",
       " 'stone': 717,\n",
       " 'package': 718,\n",
       " 'favorite': 719,\n",
       " 'slender': 720,\n",
       " 'side': 3194,\n",
       " 'act': 722,\n",
       " 'mean': 3195,\n",
       " 'nastily': 724,\n",
       " 'chivalry': 725,\n",
       " 'curling': 726,\n",
       " 'burning': 727,\n",
       " 'image': 728,\n",
       " 'legged': 729,\n",
       " 'sneering': 730,\n",
       " 'parties': 731,\n",
       " \"buyin'\": 732,\n",
       " 'telescope': 733,\n",
       " \"how's\": 734,\n",
       " 'her': 4433,\n",
       " 'sloped': 736,\n",
       " 'sides': 1156,\n",
       " 'brazilian': 738,\n",
       " 'hem': 739,\n",
       " 'ago': 1157,\n",
       " 'complete': 741,\n",
       " 'n-nothing': 742,\n",
       " 'gliding': 743,\n",
       " 'foreheads': 744,\n",
       " 'Harry': 745,\n",
       " 'mice': 746,\n",
       " 'with': 747,\n",
       " 'buying': 748,\n",
       " 'handsome': 749,\n",
       " \"they're\": 750,\n",
       " 'rush': 751,\n",
       " 'rage': 752,\n",
       " 'tripe': 753,\n",
       " 'rags': 754,\n",
       " 'dirty': 755,\n",
       " 'he-': 756,\n",
       " 'agree': 757,\n",
       " 'gone': 758,\n",
       " 'fright': 759,\n",
       " 'exhausted': 760,\n",
       " 'certain': 761,\n",
       " 'am': 762,\n",
       " 'an': 763,\n",
       " 'wildly': 4859,\n",
       " 'as': 764,\n",
       " 'carved': 765,\n",
       " 'fumbling': 766,\n",
       " 'watched': 767,\n",
       " 'tremble': 768,\n",
       " 'cream': 769,\n",
       " 'beaming': 770,\n",
       " 'drafts': 771,\n",
       " 'drafty': 772,\n",
       " 'tight': 773,\n",
       " 'beaks': 774,\n",
       " 'waving': 775,\n",
       " 'herbs': 776,\n",
       " 'snitch': 777,\n",
       " 'tricky': 778,\n",
       " 'sobbing': 779,\n",
       " 'tricks': 780,\n",
       " 'hello': 1162,\n",
       " 'hushed': 3205,\n",
       " '(it': 783,\n",
       " 'birdcage': 784,\n",
       " 'beware': 785,\n",
       " 'code': 786,\n",
       " '(if': 787,\n",
       " 'hunting': 788,\n",
       " 'laughing': 4253,\n",
       " 'to': 789,\n",
       " 'tail': 790,\n",
       " 'chewing': 791,\n",
       " 'th': 792,\n",
       " 'smile': 793,\n",
       " 'sc-': 794,\n",
       " 'case': 5357,\n",
       " 'returned': 796,\n",
       " 'detention': 797,\n",
       " 'floated': 798,\n",
       " 'dodged': 4824,\n",
       " 'large': 800,\n",
       " 'harry': 801,\n",
       " 'small': 802,\n",
       " 'dodges': 803,\n",
       " 'sank': 804,\n",
       " 'quicker': 805,\n",
       " 'past': 806,\n",
       " 'carriages': 807,\n",
       " 'pass': 808,\n",
       " 'clock': 809,\n",
       " 'poisonous': 810,\n",
       " 'whirled': 811,\n",
       " 'nurse': 812,\n",
       " 'full': 813,\n",
       " 'escaping': 814,\n",
       " \"lecturin'\": 815,\n",
       " 'leaping': 816,\n",
       " 'hours': 817,\n",
       " 'november': 818,\n",
       " 'legend': 819,\n",
       " 'cock-and-bull': 4971,\n",
       " 'windowsill': 1170,\n",
       " 'experience': 822,\n",
       " 'pick': 823,\n",
       " 'smuggle': 824,\n",
       " 'rummaging': 825,\n",
       " 'gawking': 826,\n",
       " 'followed': 827,\n",
       " 'hook-nosed': 828,\n",
       " 'indoors': 829,\n",
       " 'periodmarkfor': 830,\n",
       " 'bagshot': 831,\n",
       " 'more': 832,\n",
       " 'door': 833,\n",
       " 'company': 834,\n",
       " 'spoils': 835,\n",
       " 'doom': 836,\n",
       " 'cunning': 837,\n",
       " 'sizing': 838,\n",
       " 'keeping': 839,\n",
       " 'snuffling': 2214,\n",
       " 'science': 841,\n",
       " 'stalagmite': 842,\n",
       " \"fang's\": 843,\n",
       " 'learn': 844,\n",
       " 'knocked': 845,\n",
       " 'beautiful': 846,\n",
       " 'accept': 847,\n",
       " 'flitwicles': 848,\n",
       " 'fiercely': 849,\n",
       " 'sense': 850,\n",
       " 'disliked': 5185,\n",
       " 'dress': 852,\n",
       " 'tapestry': 853,\n",
       " 'huge': 5191,\n",
       " 'glowing': 855,\n",
       " 'creature': 856,\n",
       " 'waved': 857,\n",
       " 'plant': 858,\n",
       " \"hagrid's\": 859,\n",
       " 'countryside': 860,\n",
       " 'mended': 861,\n",
       " 'director': 5378,\n",
       " 'waves': 862,\n",
       " 'pleaded': 863,\n",
       " 'flutter': 864,\n",
       " 'refuse': 865,\n",
       " 'twisting': 866,\n",
       " 'tentacles': 867,\n",
       " 'deafening': 868,\n",
       " 'helplessly': 869,\n",
       " 'replied': 870,\n",
       " 'rocketed': 5298,\n",
       " 'bowl': 872,\n",
       " 'paper': 873,\n",
       " 'brim': 874,\n",
       " 'signs': 875,\n",
       " 'smiling': 876,\n",
       " 'its': 877,\n",
       " 'roots': 878,\n",
       " 'rapidly': 879,\n",
       " 'sauce': 880,\n",
       " 'goggle': 3458,\n",
       " \"it'\": 882,\n",
       " 'snowball': 883,\n",
       " 'weeds': 884,\n",
       " 'sucked': 885,\n",
       " 'stewed': 886,\n",
       " 'always': 887,\n",
       " 'all-': 888,\n",
       " 'isle': 5375,\n",
       " 'found': 890,\n",
       " 'england': 891,\n",
       " 'upstairs': 892,\n",
       " 'bendy': 893,\n",
       " 'really': 894,\n",
       " 'try': 1190,\n",
       " 'missed': 896,\n",
       " 'candlelight': 897,\n",
       " 'misses': 898,\n",
       " 'levi-o-sa': 3228,\n",
       " 'darling': 900,\n",
       " 'plotting': 901,\n",
       " 'highway': 902,\n",
       " 'nervously': 903,\n",
       " 'bungler': 904,\n",
       " 'drifting': 905,\n",
       " 'murmur': 906,\n",
       " 'imagine': 907,\n",
       " 'bumped': 908,\n",
       " 'pairs': 909,\n",
       " 'reared': 910,\n",
       " 'scoop)': 911,\n",
       " 'castle': 912,\n",
       " \"door's\": 913,\n",
       " 'gazed': 914,\n",
       " 'rooted': 915,\n",
       " 'slipped': 916,\n",
       " 'wilder': 917,\n",
       " 'girls': 3231,\n",
       " 'number': 919,\n",
       " 'murmured': 920,\n",
       " 'guess': 921,\n",
       " 'heads': 922,\n",
       " 'jet': 923,\n",
       " 'swipe': 924,\n",
       " 'threatening': 925,\n",
       " 'flimsy': 926,\n",
       " 'forevermore': 927,\n",
       " 'erupted': 928,\n",
       " 'codswallop': 929,\n",
       " 'rain': 4839,\n",
       " 'stairs': 930,\n",
       " 'determined': 931,\n",
       " 'remembers': 932,\n",
       " \"wizardin'\": 933,\n",
       " 'mossy': 934,\n",
       " 'man-crushing': 935,\n",
       " 'guarding': 936,\n",
       " 'blond': 937,\n",
       " 'cleverness': 938,\n",
       " 'sell': 939,\n",
       " 'scrawled': 940,\n",
       " 'Hannah': 941,\n",
       " 'odd': 942,\n",
       " 'silvery': 943,\n",
       " 'also': 944,\n",
       " \"hour's\": 945,\n",
       " 'shops': 5364,\n",
       " 'seized': 946,\n",
       " 'play': 947,\n",
       " 'firsthand': 948,\n",
       " 'blackboard': 949,\n",
       " 'swiftly': 950,\n",
       " 'unused': 951,\n",
       " \"guardin'\": 952,\n",
       " 'plan': 953,\n",
       " 'bustled': 954,\n",
       " \"baron'll\": 955,\n",
       " 'singled': 956,\n",
       " 'pliable': 957,\n",
       " 'seize': 958,\n",
       " 'sometimes': 959,\n",
       " 'cover': 960,\n",
       " 'barred': 961,\n",
       " 'donkeys': 962,\n",
       " 'dragged': 963,\n",
       " 'golf': 964,\n",
       " 'gold': 965,\n",
       " 'session': 967,\n",
       " \"frightenin'\": 968,\n",
       " 'writer': 969,\n",
       " 'failed': 970,\n",
       " 'columns': 971,\n",
       " 'begins': 3241,\n",
       " 'downpour': 973,\n",
       " 'sunny': 974,\n",
       " \"they'd\": 975,\n",
       " 'periodmark': 976,\n",
       " 'frightening': 977,\n",
       " 'enemy': 978,\n",
       " 'sleeve': 979,\n",
       " 'tabby': 980,\n",
       " 'bothering': 981,\n",
       " 'tottering': 982,\n",
       " \"knowin'\": 983,\n",
       " 'body': 984,\n",
       " 'delicately': 985,\n",
       " 'set': 986,\n",
       " \"'gar'\": 987,\n",
       " 'nibble': 988,\n",
       " 'grubby-looking': 989,\n",
       " 'see': 990,\n",
       " 'sec': 991,\n",
       " 'sea': 992,\n",
       " 'knees': 993,\n",
       " 'spirits': 994,\n",
       " 'currently': 995,\n",
       " 'topmost': 996,\n",
       " \"las'\": 998,\n",
       " 'nope': 999,\n",
       " 'beasts': 4329,\n",
       " 'knowing': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_index=dictionary(text_words)\n",
    "words_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sequences of 10 length (given 10 words as inputs, predict 1 word for output added to the previos words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  create_model_inputs(batch_size):\n",
    "    '''Define model inputs'''\n",
    "    \n",
    "    #Model's placeholders for inputs\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    return inputs,targets,keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def  build_RNN(vocabulary_size,embedding_size,inputs,seq_len,num_hidden,lstm_layer_numbers,keep_prob,batch_size):\n",
    "    '''Build RNN'''\n",
    "    #Embedding Layer\n",
    "    '''Intialize embeddings for the words. Embedding layer connects the words to the LSTM layers (words are embedded to the embedding_size vectors instead of vocabulary size vectors or one hot vectors). Here, provided by tensorflow, we used random_uniform distribution to create embeddings'''\n",
    "    #tf.AUTO_REUSE for reuisng the same scope for generating as for traning\n",
    "    with tf.variable_scope('rnn1', reuse=tf.AUTO_REUSE):\n",
    "        embedding = tf.Variable(tf.random_uniform((vocabulary_size, embedding_size), -1, 1))\n",
    "        embed = tf.nn.embedding_lookup(embedding, inputs)\n",
    "        #Define LSTM layers\n",
    "        lstms=[]\n",
    "        for i in range(lstm_layer_numbers):\n",
    "            lstms.append(tf.contrib.rnn.BasicLSTMCell(num_hidden))\n",
    "        # Add regularization dropout to the LSTM cells\n",
    "        drops = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob) for lstm in lstms]\n",
    "        # Stack up multiple LSTM layers\n",
    "        stacked_lstm = tf.contrib.rnn.MultiRNNCell(drops)\n",
    "        # Getting the initial state\n",
    "        initial_state = stacked_lstm.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        #outputs, final_state = tf.nn.dynamic_rnn(stacked_lstm, embed, initial_state=initial_state)\n",
    "        #need to unstack the sequence of input into a list of tensors\n",
    "        seq_input = [tf.squeeze(i,[1]) for i in tf.split(embed,seq_len,1)] \n",
    "\n",
    "        outputs, final_state = legacy_seq2seq.rnn_decoder(seq_input, initial_state, stacked_lstm, loop_function=None)\n",
    "\n",
    "    return initial_state, outputs, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(text_words,text_len,seq_len, batch_size,number_of_words_in_one_batch,n_batches):\n",
    "    '''Using generator to return batches'''\n",
    "    \n",
    "    #This makes the input data to be compatible with seq_len\n",
    "    text_all_batches = text_words[:n_batches*number_of_words_in_one_batch]\n",
    "    index_text_all_batches=[]\n",
    "    for i in text_all_batches:\n",
    "        if i in words_index:\n",
    "            index_text_all_batches.append(words_index[i])\n",
    "        \n",
    "    #index_text_all_batches={v for k,v in words_index.items() if k in text_all_batches}\n",
    "    #get word index for words for batches\n",
    "    input_seq=list(index_text_all_batches)\n",
    "    output_seq=input_seq\n",
    "    output_seq.append(output_seq.pop(output_seq[0]))\n",
    "    for ii in range(0, len(text_all_batches), number_of_words_in_one_batch):\n",
    "        yield input_seq[ii:ii+number_of_words_in_one_batch], output_seq[ii:ii+number_of_words_in_one_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Parameters\n",
    "# number of units\n",
    "n_input= len(words_index)\n",
    "num_hidden = 256\n",
    "lstm_layer_numbers=3\n",
    "embed_size=256\n",
    "batch_size= 256\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a graph for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 256, 6270)\n",
      "0\n",
      "('cost_train=', 6.938602598089922)\n",
      "100\n",
      "('cost_train=', 4.6028806473079475)\n",
      "200\n",
      "('cost_train=', 3.816319227218627)\n",
      "300\n",
      "('cost_train=', 3.613472731489884)\n",
      "400\n",
      "('cost_train=', 3.4648596424805489)\n",
      "500\n",
      "('cost_train=', 3.3783038101698226)\n",
      "600\n",
      "('cost_train=', 3.2768038762243168)\n",
      "700\n",
      "('cost_train=', 3.2028994121049585)\n",
      "800\n",
      "('cost_train=', 3.1575366070396025)\n",
      "900\n",
      "('cost_train=', 3.1641998541982543)\n",
      "1000\n",
      "('cost_train=', 3.1053596609517147)\n",
      "1100\n",
      "('cost_train=', 3.0415823145916594)\n",
      "1200\n",
      "('cost_train=', 2.9972305548818485)\n",
      "1300\n",
      "('cost_train=', 3.0092376094115414)\n",
      "1400\n",
      "('cost_train=', 2.9771042936726619)\n",
      "1500\n",
      "('cost_train=', 2.9253121300747522)\n",
      "1600\n",
      "('cost_train=', 2.939032611094023)\n",
      "1700\n",
      "('cost_train=', 2.922185113555507)\n",
      "1800\n",
      "('cost_train=', 2.9919576770380925)\n",
      "1900\n",
      "('cost_train=', 2.9595746617568164)\n",
      "2000\n",
      "('cost_train=', 2.8673423842379928)\n",
      "2100\n",
      "('cost_train=', 2.8765910675651156)\n",
      "2200\n",
      "('cost_train=', 2.966701865196228)\n",
      "2300\n",
      "('cost_train=', 2.8635740091926176)\n",
      "2400\n",
      "('cost_train=', 2.8589728694213057)\n",
      "2500\n",
      "('cost_train=', 2.8918192072918543)\n"
     ]
    }
   ],
   "source": [
    "graph0 = tf.Graph()\n",
    "#There exits a global default graph created by tenserflow, for new graphs we need to set them as a default graph\n",
    "with graph0.as_default():\n",
    "    inputs,targets,keep_prob=create_model_inputs(batch_size)\n",
    "    initial_state, outputs, final_state = build_RNN(n_input,embed_size,inputs,seq_len,num_hidden,lstm_layer_numbers,keep_prob,batch_size)\n",
    "    # Loss and optimizer\n",
    "    logits = tf.contrib.layers.fully_connected(outputs, n_input, activation_fn=None)\n",
    "    \n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "    print(probs.shape)\n",
    "    cost =  tf.contrib.seq2seq.sequence_loss(\n",
    "            logits,\n",
    "            targets,\n",
    "            tf.ones([batch_size, (seq_len)])    \n",
    "        )                                   \n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "    # Using gradian clipping for exploding gradients\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients) \n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "#Execute the graph for training\n",
    "with tf.Session(graph=graph0) as sess:\n",
    "    sess = tf.Session(graph=graph0)\n",
    "    sess.run(init_op)\n",
    "    number_of_words_in_one_batch= seq_len*batch_size\n",
    "    n_batches = text_len//number_of_words_in_one_batch\n",
    "    epochs = 5501\n",
    "    for epoch in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        avg_cost_train = 0 \n",
    "        avg_acc_train= 0\n",
    "        for ii, (x, y) in enumerate(get_batches(text_words,text_len,seq_len,batch_size,number_of_words_in_one_batch,n_batches), 1):\n",
    "            #need to reshape y to feed it to targets\n",
    "            y = np.array(y).reshape(batch_size,(seq_len))\n",
    "            x = np.array(x).reshape(batch_size,(seq_len))\n",
    "\n",
    "            state, loss, _= sess.run([final_state, cost,train_op], feed_dict={inputs: x,\n",
    "                                                            targets: y,keep_prob: 0.8,initial_state: state})\n",
    "\n",
    "            avg_cost_train += loss / n_batches\n",
    "        if(epoch%100==0):\n",
    "            print(epoch)\n",
    "            print(\"cost_train=\", avg_cost_train) \n",
    "    #Save the model into a file \n",
    "    checkpoint=\"./model/savedmodel.ckpt\"\n",
    "    save_path = saver.save(sess, checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "#use the same sequence length as for trained model to generate the new words\n",
    "seq_len=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Craete a graph for generating text<br>\n",
    "Based on the train model, each time it uses 10 previous words to generate the next word (therfore, first define 10 prime words to begin generating 11th word and then consider 2th to 11th words for generating the 12th word and so on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/savedmodel.ckpt\n",
      "['Harry', 'Potter', 'went', 'to', 'see', 'the', 'street', 'even', 'it', 'was']\n",
      "Harry Potter went to see the street even it was however went the find was for the that , down boys . . . give . seven have . . grunt pile \n",
      " door relief , mirror , . , . strong , . , open . and . white want , . no . head air . . about and . one \n",
      " coming except . . it minute felt , . , time . want behind said . , , . have . , , few speed ones Harry , the very . reached . except started said \n",
      " , to usual youngest . not , only money . plant , , quidditch . light , don't . . . . , lot and fell get off nose wanted and insisting sorry . . us . other neville , what curiously . drew however your going , , . like . expelled have a what muffled . . , , give \n",
      " who , , , \n",
      " golden disappeared the . . there remember extra \n",
      " stolen won . \n",
      " , \n",
      " is \n",
      " \n",
      " mark \n",
      " reason in before \n",
      " . . \n",
      " . , , it , . ron's . , knuts move \n",
      " , he tune go , you'll \n",
      " \n",
      " . . us . almost made than \n",
      " Hedwig . \n",
      " \n",
      " \n",
      " saying , leaves . showing , branches , , . mind , nimbus staring me field shelf watched always . ? as time \n",
      " , words table , do tasty , noise , las' gryffindor the . last \n",
      " , knobbly \n",
      " . compartment , . mirror , . . , waved , \n",
      " in tracks as . . about a . , in , hat few just ! . , . suddenly , pass \n",
      " listen , luck \n",
      " off won a of that week . . of . go another outside ground wand reaching great . standing , wood hogwarts fell \n",
      " to whispered \n",
      " \n",
      " you're \n",
      " . \n",
      " with . , again . . cloak . almost something and myself haven't top wands \n",
      " . , Weasley ever . . . . turning . but made , best lightning ter \n",
      " why studying \n",
      " \n",
      " \n",
      " \n",
      " through . hall almost . goyle , you behind once . \n",
      " . your \n",
      " , \n",
      " whoop , , matter \n",
      " as . i've Weasley stopped . slytherin up silently . . hadn't . or . i'm he'd . quirrell's the leave yell still carefully hurrying \n",
      " the . -- you than ghost very became ask . . another brilliant , \n",
      " Filch . floor who . since too . \n",
      " \n",
      " . . . , told , . , drink . bin dark no wrongly own , . say any black read . \n",
      " \n",
      " remember , the famous . \n",
      " . . , never . . minded . , , fly \n",
      " , , . see excited , \n",
      " \n",
      " . plump , shoulders her . ? the himself \n",
      " to , . or \n",
      " into , , , Harry , . them , once \n",
      " \n",
      " cup \n",
      " steps , \n",
      " hall plastic \n",
      " \n",
      " . trying , must kept worse Fred read my , but oh seemed semi: \n",
      " \n",
      " to ? finally platform . stone \n",
      " . fer ? . . body still it snape \n",
      " \n",
      " . he ceiling . . . . , , cloak parents pain teeth . . hair bucking \n",
      " know call . . throw the putting \n",
      " smeltings the of . find McGonagall \n",
      " \n",
      " poked more looked . in , leaves , \n",
      " . loads , paper \n",
      " , get . way can't out voice , , , moving . seen two , . pulling term , \n",
      " . \n",
      " \n",
      " bit better away \n",
      " owl , mirror \n",
      " . . . freckles , , . before do yeah twenty-six , full daily \n",
      " yourselves \n",
      " . . impatiently all nearer , \n",
      " \n",
      " , , matter \n",
      " sir . -- . opened i told . . \n",
      " -- \n",
      " , , the along keyhole . of met have twins . snape pulled very almost . \n",
      " \n",
      " broad \n",
      " . . , branches . , . , same . who , uncle \n",
      " train , , \n",
      " feet twins , oliver \n",
      " door a . , , . , , it think climbed \n",
      " \n",
      " , , behind is the . full . you \n",
      " \n",
      " . . , quirrell yer . , became voice where . have chess \n",
      " during dropped unwrapped \n",
      " just he . \n",
      " around who i'll . . it than . \n",
      " heard , what hand . warmth harry's don' more , \n",
      " excellent , had . . . . me in ! neville McGonagall semi: , this onto i'm him . they'll white . sending card one . want . him his that \n",
      " \n",
      " . . about down we on -- \n",
      " guide \n",
      " \n",
      " , \n",
      " . \n",
      " inside new quirrell . recognize remember . . . , father , , , , matter hurtled p-pick they \n",
      " legs \n",
      " . . . \n",
      " remember . . you your him mirror . , him try . , . \n",
      " \n",
      " only . . \n",
      " losing , just . harry's the . will waved walk . can't didn't then \n",
      " quaffle open added which powerful i \n",
      " the , \n",
      " possible end . . of . gryffindor real , . which just our go \n",
      " , . chessmen past . \n",
      " \n",
      " like rid . nearer two trying McGonagall not \n",
      " . , . move . lake across you'd . , , \n",
      " \n",
      " nervous him \n",
      " each so . save books high someone . . \n",
      " , did her . . quirrell \n",
      " myself \n",
      " cold , wasn't behind \n",
      " semi: \n",
      " followed you . all kill who . . \n",
      " wrist something who minute \n",
      " sight won\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "graph1 = tf.Graph()\n",
    "\n",
    "with graph1.as_default():\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, None], name='inputs')\n",
    "    initial_state, outputs, final_state = build_RNN(n_input,embed_size,inputs,seq_len,num_hidden,lstm_layer_numbers,keep_prob,batch_size)\n",
    "    logits = tf.contrib.layers.fully_connected(outputs, n_input, activation_fn=None)\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "    init_op1 = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "#Execute the graph1 for generating text\n",
    "with tf.Session(graph=graph1) as sess2:\n",
    "    #This part to compare varibles in checkpoints with what we have\n",
    "    var_name_list = [v.name for v in tf.trainable_variables()]\n",
    "    #print(var_name_list)\n",
    "    from tensorflow.python import pywrap_tensorflow\n",
    "\n",
    "    reader = pywrap_tensorflow.NewCheckpointReader(checkpoint)\n",
    "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "    #print(var_to_shape_map)\n",
    "    \n",
    "    #Execute the graph to generate the text\n",
    "    sess2.run(init_op1)\n",
    "    \n",
    "    #Number of words to generate \n",
    "    num_gen=1000\n",
    "    \n",
    "    # Load the model\n",
    "    saved = tf.train.import_meta_graph('./model/savedmodel.ckpt.meta')\n",
    "    saved.restore(sess2, checkpoint)\n",
    "    \n",
    "    #Just for the record \n",
    "    saved_dict = {}\n",
    "    for x in tf.trainable_variables():\n",
    "          saved_dict[x.name] = x\n",
    "    \n",
    "    #10 first words to begin with\n",
    "    start_word=\"Harry Potter went to see the street even it was\"\n",
    "    start_words=start_word.split(\" \")\n",
    "    print(start_words)\n",
    "    \n",
    "    #The sentence of text we have so far as a list of words' indexes\n",
    "    genertaed_sentence=[words_index[w] for w in start_words]\n",
    "    genertaed_sentence=[genertaed_sentence]\n",
    "    \n",
    "    state = sess2.run(initial_state)\n",
    "    #Choose the last 10 words we have from text to predict the next word\n",
    "    last_words=[(genertaed_sentence[0])[-10:]]\n",
    "    \n",
    "    \n",
    "    for i in range(0,num_gen):\n",
    "        #seq_len is 10\n",
    "        seq_len=len(last_words[0])\n",
    "        \n",
    "        #print(\"last_words\",last_words)\n",
    "        \n",
    "        next_word = np.zeros((1,seq_len))\n",
    "        next_word = [w for w in last_words]\n",
    "        #print(np.array(next_word).shape,inputs.shape,type(next_word),next_word)\n",
    "        next_word = np.asarray(next_word) \n",
    "\n",
    "        #next_word = next_word.reshape(batch_size,seq_len)\n",
    "            \n",
    "        #print(\"next_word\",next_word)\n",
    "         #next_word = np.array(next_word).reshape(batch_size,(seq_len))\n",
    "        prediction,state= sess2.run([probs,final_state], feed_dict={inputs: next_word,\n",
    "                                                                    keep_prob: 0.8,initial_state: state})\n",
    "        #print(\"Prediction's shape\",prediction.shape,\" Prediction:\",prediction)\n",
    "        #print(\"Element we choose for prediction: \",prediction[len(last_words[0])-1,0])\n",
    "        #Based on prediction's shape still not sure about part len(last_words[0])-1, which element to choose\n",
    "        \n",
    "        #Next predicted word by choosing the word with max probability\n",
    "        next_predicted_word = np.argmax(prediction[len(last_words[0])-1,0])\n",
    "        \n",
    "        #append the new word to the previous sentences\n",
    "        genertaed_sentence[0].append(next_predicted_word)\n",
    "        #save in last_word to use it in for loop\n",
    "        last_words=[(genertaed_sentence[0])[-10:]]\n",
    "\n",
    "#Conver index to words\n",
    "list_gen=[get_by_key_dict(word_int,words_index) for word_int in genertaed_sentence[0]]\n",
    "sen=' '.join(list_gen)\n",
    "#Convert back the tokens for punctuations\n",
    "sen=sen.replace(\"nextline\", \"\\n\")\n",
    "sen=sen.replace(\"periodmark\", \".\")\n",
    "sen=sen.replace(\"colonmark\", \":\")\n",
    "sen=sen.replace(\"commamark\", \",\")\n",
    "sen=sen.replace(\"semicommamark\", \";\")\n",
    "sen=sen.replace(\"questionmark\", \"?\")\n",
    "sen=sen.replace(\"exclamationmark\", \"!\")\n",
    "sen=sen.replace(\"3dots\", \"...\")\n",
    "sen=sen.replace(\"quotemark\", \"\\\"\")\n",
    "sen=sen.replace(\"leftparan\", \"(\")\n",
    "sen=sen.replace(\"rightparan\", \")\")\n",
    "#Print the whole text\n",
    "print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
